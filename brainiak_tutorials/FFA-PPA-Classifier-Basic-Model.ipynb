{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Fusiform Face Area (FFA) and Parahippocampal Place Area (PPA) through Support Vector Machines\n",
    "\n",
    "\n",
    "## Goal of this Script:\n",
    "The goal of this script is to use fMRI data to train a classifier that can differentiate between when a subject is looking at a face, a scene, or an object. Use this knowledge to explore the neurological function of the appropriate brain regions. \n",
    "\n",
    "## Methodology:\n",
    ">1. Assign labels to every time-point (TR) in the dataset.\n",
    ">2. Time-shift the signal to be classified, taking into consideration the delayed hemodynamic response.\n",
    ">3. Collect BOLD data for all runs into one array.\n",
    ">4. Test out a classifier (SVM) on a group of subjects with a fixed set of parameters.\n",
    ">5. Replicate the analysis that led to the modular vs. distributed processing debate.\n",
    "\n",
    "\n",
    "## Table of Contents:\n",
    "\n",
    "* [0. Neuroimaging](#neuro_imaging)\n",
    "    * [0.1 Fusiform Face Area Mask for Subject 1](#s1_ffa_mask)\n",
    "    * [0.2 Parahippocampal Place Area Mask for Subject 1](#s1_ppa_mask)\n",
    "    * [0.3 Interactive View of a Parahippocampal Place Area Mask](#interactive_ppa_mask)\n",
    "    * [0.4 Functional Bold Data from Subject 1 on Day 2](#s1_d2_bold_data)\n",
    "    * [0.5 Interactive View of fMRI](#interactive_fmri)\n",
    "    * [0.6 Anatomical Data from Subject 1 on Day 2](#s1_d2_anatom_data)\n",
    "\n",
    "\n",
    "* [1. Loading and Normalization](#load_data)\n",
    "    * [1.1 NEED TITLE](#1.1)\n",
    "    * [1.2 NEED TITLE](#1.2)\n",
    "    * [1.3 Hemodynamic Lag](#hemodynamic_lag)\n",
    "    * [1.4 Load the fMRI Data](#load_fmri_data)\n",
    "\n",
    "\n",
    "* [2. Classification](#classification)  \n",
    "    * [2.1 Reshape Data](#reshape_data)\n",
    "    * [2.2 Leave-One-Run-Out (LORO) Training and Testing](#loro_training_testing)\n",
    "    * [2.3 Normalization](#normalization)\n",
    "    * [2.4 Classifiers](#classifiers)\n",
    "\n",
    "\n",
    "* [3. Modular vs Distributed Processing](#modular_vs_distributed)\n",
    "    * [3.1. Prepare Data for Loading](#prepare_data)\n",
    "    * [3.2 Decoding the Fusiform Face Area (FFA)](#decoding_ffa)\n",
    "    * [3.3 Decoding the Parrahippocampal Place Area (PPA)](#decoding_ppa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset: \n",
    "For this script we will use the localizer dataset from [Kim et al. (2017)](https://doi.org/10.1523/JNEUROSCI.3272-16.2017). \n",
    "\n",
    "### General Overview:\n",
    "Localizer task where neural activation of participants was measured when presented with an image of a face, a scene, or an object. \n",
    "\n",
    "### Description:\n",
    "The localizer consisted of 3 runs with 5 blocks of each category (faces, scenes and objects) per run. Each block was presented for 15s. Within a block, a stimulus was presented every 1.5s (1 TR). Between blocks, there was 15s (10 TRs) of fixation. Each run was 310 TRs. In the MATLAB stimulus file, the first row codes for the stimulus category for each trial (1 = Faces, 2 = Scenes, 3 = Objects). The 3rd row contains the time (in seconds, relative to the start of the run) when the stimulus was presented for each trial. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(5000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 5 seconds\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import sys \n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "import os \n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from nilearn.input_data import NiftiMasker\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from brainiak.utils.fmrisim import _double_gamma_hrf as hrf_func\n",
    "from brainiak.utils import fmrisim as sim\n",
    "\n",
    "# load some helper functions\n",
    "from utils import load_vdc_mask, load_vdc_epi_data, load_vdc_masked_data \n",
    "from utils import vdc_data_dir, vdc_all_ROIs, vdc_label_dict, vdc_n_runs, vdc_hrf_lag, vdc_TR, vdc_TRs_run # load some constants\n",
    "\n",
    "%matplotlib inline \n",
    "%autosave 5\n",
    "sns.set(style = 'white', context='poster', rc={\"lines.linewidth\": 2.5})\n",
    "sns.set(palette=\"colorblind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some constants, which is specific to the VDC data:\n",
      "data dir = /Users/SeanTraynor/Downloads/brainiak_datasets/vdc\n",
      "ROIs = ['FFA', 'PPA']\n",
      "Labels = {1: 'Faces', 2: 'Scenes', 3: 'Objects'}\n",
      "number of runs = 3\n",
      "1 TR = 1.50 sec\n",
      "HRF lag = 4.50 sec\n",
      "num TRs per run = 310\n"
     ]
    }
   ],
   "source": [
    "print('Here are some constants, which is specific to the VDC data:')\n",
    "print('data dir = %s' % (vdc_data_dir))\n",
    "print('ROIs = %s' % (vdc_all_ROIs))\n",
    "print('Labels = %s' % (vdc_label_dict))\n",
    "print('number of runs = %s' % (vdc_n_runs))\n",
    "print('1 TR = %.2f sec' % (vdc_TR))\n",
    "print('HRF lag = %.2f sec' % (vdc_hrf_lag))\n",
    "print('num TRs per run = %d' % (vdc_TRs_run))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory structure of the VDC dataset\n",
    "header_file=os.path.join(vdc_data_dir,'README.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Neuroimaging: <a id=\"neuro_imaging\"></a>\n",
    "\n",
    "The below cells illustrate the localized masks of the participants' brain regions using nilearn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Fusiform Face Area Mask for Subject 1 <a id=\"s1_ffa_mask\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File not found: '/Users/aratzan/Downloads/brainiak_datasets/vdc/sub-01/preprocessed/masks/sub-01_ventral_FFA_locColl_to_epi1.nii.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-84f3164a8635>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mffa_mask_s1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/aratzan/Downloads/brainiak_datasets/vdc/sub-01/preprocessed/masks/sub-01_ventral_FFA_locColl_to_epi1.nii.gz'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplotting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_glass_brain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffa_mask_s1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/nilearn/plotting/img_plotting.py\u001b[0m in \u001b[0;36mplot_glass_brain\u001b[0;34m(stat_map_img, output_file, display_mode, colorbar, figure, axes, title, threshold, annotate, black_bg, cmap, alpha, vmin, vmax, plot_abs, symmetric_cbar, resampling_interpolation, **kwargs)\u001b[0m\n\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstat_map_img\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1172\u001b[0;31m         \u001b[0mstat_map_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_niimg_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstat_map_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mplot_abs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m             cbar_vmin, cbar_vmax, vmin, vmax = _get_colorbar_and_data_ranges(\n",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg_3d\u001b[0;34m(niimg, dtype)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0mIts\u001b[0m \u001b[0mapplication\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0midempotent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \"\"\"\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcheck_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File not found: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mniimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File not found: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mniimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: File not found: '/Users/aratzan/Downloads/brainiak_datasets/vdc/sub-01/preprocessed/masks/sub-01_ventral_FFA_locColl_to_epi1.nii.gz'"
     ]
    }
   ],
   "source": [
    "from nilearn import plotting\n",
    "\n",
    "ffa_mask_s1 = '/Users/aratzan/Downloads/brainiak_datasets/vdc/sub-01/preprocessed/masks/sub-01_ventral_FFA_locColl_to_epi1.nii.gz'\n",
    "\n",
    "plotting.plot_glass_brain(ffa_mask_s1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Parahippocampal Place Area Mask for Subject 1 <a id=\"s1_ppa_mask\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File not found: '/Users/aratzan/Downloads/brainiak_datasets/vdc/sub-01/preprocessed/masks/sub-01_ventral_PPA_locColl_to_epi1.nii.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7acc81ea6dea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mppa_mask_s1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/aratzan/Downloads/brainiak_datasets/vdc/sub-01/preprocessed/masks/sub-01_ventral_PPA_locColl_to_epi1.nii.gz'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplotting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_glass_brain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mppa_mask_s1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/nilearn/plotting/img_plotting.py\u001b[0m in \u001b[0;36mplot_glass_brain\u001b[0;34m(stat_map_img, output_file, display_mode, colorbar, figure, axes, title, threshold, annotate, black_bg, cmap, alpha, vmin, vmax, plot_abs, symmetric_cbar, resampling_interpolation, **kwargs)\u001b[0m\n\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstat_map_img\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1172\u001b[0;31m         \u001b[0mstat_map_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_niimg_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstat_map_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mplot_abs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m             cbar_vmin, cbar_vmax, vmin, vmax = _get_colorbar_and_data_ranges(\n",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg_3d\u001b[0;34m(niimg, dtype)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0mIts\u001b[0m \u001b[0mapplication\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0midempotent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \"\"\"\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcheck_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File not found: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mniimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File not found: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mniimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: File not found: '/Users/aratzan/Downloads/brainiak_datasets/vdc/sub-01/preprocessed/masks/sub-01_ventral_PPA_locColl_to_epi1.nii.gz'"
     ]
    }
   ],
   "source": [
    "ppa_mask_s1 = '/Users/aratzan/Downloads/brainiak_datasets/vdc/sub-01/preprocessed/masks/sub-01_ventral_PPA_locColl_to_epi1.nii.gz'\n",
    "plotting.plot_glass_brain(ppa_mask_s1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 Interactive View of a Parahippocampal Place Area Mask <a id=\"interactive_ppa_mask\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File not found: '/Users/aratzan/Downloads/brainiak_datasets/vdc/sub-01/preprocessed/masks/sub-01_ventral_PPA_locColl_to_epi1.nii.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b5d79ded24c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplotting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mppa_mask_s1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/nilearn/plotting/html_stat_map.py\u001b[0m in \u001b[0;36mview_img\u001b[0;34m(stat_map_img, bg_img, cut_coords, colorbar, title, threshold, annotate, draw_cross, black_bg, cmap, symmetric_cmap, dim, vmax, vmin, resampling_interpolation, opacity, **kwargs)\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Prepare the color map and thresholding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     mask_img, stat_map_img, data, threshold = _mask_stat_map(\n\u001b[0;32m--> 455\u001b[0;31m         stat_map_img, threshold)\n\u001b[0m\u001b[1;32m    456\u001b[0m     colors = colorscale(cmap, data.ravel(), threshold=threshold,\n\u001b[1;32m    457\u001b[0m                         \u001b[0msymmetric_cmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msymmetric_cmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/nilearn/plotting/html_stat_map.py\u001b[0m in \u001b[0;36m_mask_stat_map\u001b[0;34m(stat_map_img, threshold)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \"\"\"\n\u001b[1;32m    137\u001b[0m     \u001b[0;31m# Load stat map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0mstat_map_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_niimg_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstat_map_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_safe_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstat_map_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg_3d\u001b[0;34m(niimg, dtype)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0mIts\u001b[0m \u001b[0mapplication\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0midempotent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \"\"\"\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcheck_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File not found: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mniimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File not found: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mniimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: File not found: '/Users/aratzan/Downloads/brainiak_datasets/vdc/sub-01/preprocessed/masks/sub-01_ventral_PPA_locColl_to_epi1.nii.gz'"
     ]
    }
   ],
   "source": [
    "plotting.view_img(ppa_mask_s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.4 Functional Bold Data from Subject 1 on Day 2 <a id=\"s1_d2_bold_data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During certain imaging tasks it can be useful to show average brain activity over the course of a trial. The below cells illustrate plots of meanEPI imaging. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File not found: '/Users/aratzan/Downloads/brainiak_datasets/vdc/sub-01/ses-day2/func/sub-01_ses-day2_task-localizer_run-02_bold.nii.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-dce8eee2929b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfunc_data_s1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/aratzan/Downloads/brainiak_datasets/vdc/sub-01/ses-day2/func/sub-01_ses-day2_task-localizer_run-02_bold.nii.gz'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmeanEPI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_data_s1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0msmoothMean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmooth_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeanEPI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfwhm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplotting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_epi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmoothMean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/nilearn/image/image.py\u001b[0m in \u001b[0;36mmean_img\u001b[0;34m(imgs, target_affine, target_shape, verbose, n_jobs)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0mimgs_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m     \u001b[0mfirst_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;31m# Compute the first mean to retrieve the reference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File not found: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mniimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File not found: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mniimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: File not found: '/Users/aratzan/Downloads/brainiak_datasets/vdc/sub-01/ses-day2/func/sub-01_ses-day2_task-localizer_run-02_bold.nii.gz'"
     ]
    }
   ],
   "source": [
    "from nilearn.image import mean_img\n",
    "from nilearn import image \n",
    "\n",
    "func_data_s1 = '/Users/aratzan/Downloads/brainiak_datasets/vdc/sub-01/ses-day2/func/sub-01_ses-day2_task-localizer_run-02_bold.nii.gz'\n",
    "meanEPI = mean_img(func_data_s1)\n",
    "smoothMean = image.smooth_img(meanEPI, fwhm=5)\n",
    "plotting.plot_epi(smoothMean) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.5 Interactive View of fMRI (background brain image used to help orient) <a id=\"interactive_fmri\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'meanEPI' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-cb94c84cc86c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplotting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeanEPI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'meanEPI' is not defined"
     ]
    }
   ],
   "source": [
    "plotting.view_img(meanEPI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.6 Anatomical Data from Subject 1 on Day 2 <a id=\"s1_d2_anatom_data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File not found: '/Users/aratzan/Downloads/brainiak_datasets/vdc/sub-01/ses-day2/anat/sub-01_ses-day2_T1w.nii.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-932244f8e500>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0manat_data_s1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/aratzan/Downloads/brainiak_datasets/vdc/sub-01/ses-day2/anat/sub-01_ses-day2_T1w.nii.gz'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplotting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manat_data_s1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/nilearn/plotting/html_stat_map.py\u001b[0m in \u001b[0;36mview_img\u001b[0;34m(stat_map_img, bg_img, cut_coords, colorbar, title, threshold, annotate, draw_cross, black_bg, cmap, symmetric_cmap, dim, vmax, vmin, resampling_interpolation, opacity, **kwargs)\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Prepare the color map and thresholding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     mask_img, stat_map_img, data, threshold = _mask_stat_map(\n\u001b[0;32m--> 455\u001b[0;31m         stat_map_img, threshold)\n\u001b[0m\u001b[1;32m    456\u001b[0m     colors = colorscale(cmap, data.ravel(), threshold=threshold,\n\u001b[1;32m    457\u001b[0m                         \u001b[0msymmetric_cmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msymmetric_cmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/nilearn/plotting/html_stat_map.py\u001b[0m in \u001b[0;36m_mask_stat_map\u001b[0;34m(stat_map_img, threshold)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \"\"\"\n\u001b[1;32m    137\u001b[0m     \u001b[0;31m# Load stat map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0mstat_map_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_niimg_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstat_map_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_safe_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstat_map_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg_3d\u001b[0;34m(niimg, dtype)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0mIts\u001b[0m \u001b[0mapplication\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0midempotent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \"\"\"\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcheck_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File not found: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mniimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File not found: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mniimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: File not found: '/Users/aratzan/Downloads/brainiak_datasets/vdc/sub-01/ses-day2/anat/sub-01_ses-day2_T1w.nii.gz'"
     ]
    }
   ],
   "source": [
    "anat_data_s1 = '/Users/aratzan/Downloads/brainiak_datasets/vdc/sub-01/ses-day2/anat/sub-01_ses-day2_T1w.nii.gz'\n",
    "plotting.view_img(anat_data_s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and Normalization<a id=\"load_data\"></a>\n",
    "\n",
    "Load and visualize the experiment labels and load the brain data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Experiment Labels <a id=\"label_data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = 'sub-01';\n",
    "\n",
    "# Function for loading in the labels\n",
    "def load_vdc_stim_labels(vdc_data_dir, subject_id):\n",
    "    stim_label = [];\n",
    "    stim_label_concatenated = [];\n",
    "    for run in range(1, vdc_n_runs+1):\n",
    "        in_file = os.path.join(vdc_data_dir,subject_id,'ses-day2','design_matrix','%s_localizer_0%d.mat' % \n",
    "                               (subject_id, run))\n",
    "        # Load in data from MATLAB\n",
    "        stim_label = scipy.io.loadmat(in_file);\n",
    "        stim_label = np.array(stim_label['data']);\n",
    "\n",
    "        # Store the data\n",
    "        if run == 1:\n",
    "            stim_label_concatenated = stim_label;\n",
    "        else:       \n",
    "            stim_label_concatenated = np.hstack((stim_label_concatenated, stim_label))\n",
    "    print(\"Loaded labels for\", subject_id)\n",
    "    return stim_label_concatenated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 NEED TITLE <a id=\"1.1\"></a>\n",
    "We now want to call this function and get its outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/SeanTraynor/Downloads/brainiak_datasets/vdc/sub-01/ses-day2/design_matrix/sub-01_localizer_01.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/SeanTraynor/Downloads/brainiak_datasets/vdc/sub-01/ses-day2/design_matrix/sub-01_localizer_01.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-777a23eccee8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load in the labels of the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstim_label_allruns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_vdc_stim_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvdc_data_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-f05f286513b0>\u001b[0m in \u001b[0;36mload_vdc_stim_labels\u001b[0;34m(vdc_data_dir, subject_id)\u001b[0m\n\u001b[1;32m      9\u001b[0m                                (subject_id, run))\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# Load in data from MATLAB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mstim_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mstim_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstim_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \"\"\"\n\u001b[1;32m    206\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m     \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m     \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmdict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mmat_reader_factory\u001b[0;34m(file_name, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \"\"\"\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mbyte_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mmjv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_matfile_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmjv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reader needs file name or open file-like object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/SeanTraynor/Downloads/brainiak_datasets/vdc/sub-01/ses-day2/design_matrix/sub-01_localizer_01.mat'"
     ]
    }
   ],
   "source": [
    "# Load in the labels of the data\n",
    "stim_label_allruns = load_vdc_stim_labels(vdc_data_dir, sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 NEED TITLE <a id=\"1.2\"></a>\n",
    "Function to return a list of category labels, one for each TR in chronological order: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label2TR(all_stim_labels, num_runs, TR, TRs_run):\n",
    "    \n",
    "    stim_label_TR = np.zeros((TRs_run * 3, 1))\n",
    "    \n",
    "    _, events = all_stim_labels.shape\n",
    "    events_run = int(events / num_runs)\n",
    "    \n",
    "    for run in range(num_runs): #run 0, 1, 2\n",
    "    # Cycle through each element in a run\n",
    "        for i in range(events_run):\n",
    "            # What element in the concatenated timing file are we accessing\n",
    "            time_idx = run * (events_run) + i \n",
    "            \n",
    "            # What is the time stamp\n",
    "            time = all_stim_labels[2, time_idx] #row 3, col...; ends up indexing out of bounds\n",
    "\n",
    "            # What TR does this timepoint refer to?\n",
    "            TR_idx = int(time / TR) + (run * (TRs_run - 1)) #TR num\n",
    "\n",
    "            # Add the condition label to this timepoint\n",
    "            stim_label_TR[TR_idx] = all_stim_labels[0, time_idx]\n",
    "            \n",
    "    return stim_label_TR\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1.3 Hemodynamic Lag: Time Shift the Labels <a id=\"hemodynamic_lag\"></a>\n",
    "\n",
    "The BOLD response that we measure with fMRI is slow to emerge after the onset of a stimulus, also known as the \"hemodynamic lag\". Below we plot the expected BOLD response to a single experimental event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3.2 Time shift the VDC labels**  \n",
    "It takes approximately 4-6s for the BOLD response to peak after an event. Hence the brain's activity does not reflect what is occuring in the world currently, but rather what occurred in the recent past. To account for the hemodynamic lag, we can shift the timecourse of labels such that they correspond in time with the future brain response they produce. First let's plot this timecourse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stim_label_allruns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-f4950cf1696d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Create a sequence of timepoints that a TR occurred on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtr_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvdc_TRs_run\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1.5\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtime_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstim_label_allruns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstim_label_allruns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stim_label_allruns' is not defined"
     ]
    }
   ],
   "source": [
    "n_conditions = len(vdc_label_dict)\n",
    "cur_pals = sns.color_palette('colorblind', n_colors=n_conditions)\n",
    "\n",
    "# Create a sequence of timepoints that a TR occurred on\n",
    "tr_time = np.arange(0, (vdc_TRs_run - 1) * 1.5 + 1, 1.5)\n",
    "time_vals = stim_label_allruns[2, 0:150]\n",
    "labels = stim_label_allruns[0, 0:150]\n",
    "\n",
    "f, ax = plt.subplots(1,1, figsize = (14, 5))\n",
    "    \n",
    "# plot the label for each condition\n",
    "for i_cond in range(n_conditions): \n",
    "    label = list(vdc_label_dict.keys())[i_cond]\n",
    "    temp_mask = label == labels\n",
    "    ax.scatter(time_vals[temp_mask], labels[temp_mask], \n",
    "               color = cur_pals[i_cond], marker = 'o')\n",
    "ax.legend(vdc_label_dict.values())\n",
    "    \n",
    "# plot the stimuli as a line \n",
    "# ax.plot(time_vals, labels, color = 'black', alpha = .5)\n",
    "ax.plot(tr_time, stim_label_TR[0:vdc_TRs_run, 0], c='orange', alpha = .5)\n",
    "\n",
    "ax.set_yticks(list(vdc_label_dict.keys()))\n",
    "ax.set_yticklabels(vdc_label_dict.values())\n",
    "\n",
    "ax.set_title('Stimulus Presentation for Run 1')\n",
    "ax.set_xlabel('Time (seconds)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to incorporate this time-shift when we extract the BOLD signal for classification (so that the labels apply to the correct brain images). One way to accomplish this is to shift the labels and extract the BOLD signal for the non-zero labels. Given that one TR = 1.5 s and the typical hemodynamic lag is 4-5 s, we will shift the labels forwards by 3 TRs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of time shift: 4.5\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'stim_label_TR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-38cba59f6ccf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Apply the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mstim_label_TR_shifted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshift_timing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstim_label_TR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stim_label_TR' is not defined"
     ]
    }
   ],
   "source": [
    "# Shift the data a certain amount\n",
    "print('Amount of time shift: %0.1f' % vdc_hrf_lag) # In seconds what is the lag between a stimulus onset and the peak bold response\n",
    "shift_size = int(vdc_hrf_lag / vdc_TR)  # Convert the shift into TRs\n",
    "\n",
    "# Create a function to shift the size\n",
    "def shift_timing(label_TR, TR_shift_size):\n",
    "    \n",
    "    # Create a short vector of extra zeros\n",
    "    zero_shift = np.zeros((TR_shift_size, 1))\n",
    "\n",
    "    # Zero pad the column from the top\n",
    "    label_TR_shifted = np.vstack((zero_shift, label_TR))\n",
    "\n",
    "    # Don't include the last rows that have been shifted out of the time line\n",
    "    label_TR_shifted = label_TR_shifted[0:label_TR.shape[0],0]\n",
    "    \n",
    "    return label_TR_shifted\n",
    "\n",
    "# Apply the function\n",
    "stim_label_TR_shifted = shift_timing(stim_label_TR, shift_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stim_label_TR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-1f172229f73e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#boxcar plot with hemodynamic lag incorporated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstim_label_TR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mvdc_TRs_run\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstim_label_TR_shifted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m310\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'orange'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stim_label_TR' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#boxcar plot with hemodynamic lag incorporated \n",
    "f, ax = plt.subplots(1,1, figsize = (12,5))\n",
    "ax.plot(tr_time, stim_label_TR[0:vdc_TRs_run, 0], c='blue',alpha=0.2)\n",
    "ax.plot(tr_time, stim_label_TR_shifted[0:310], c='orange')\n",
    "\n",
    "ax.set_ylabel('Stimuli labels')\n",
    "ax.set_xlabel('TR')\n",
    "\n",
    "plt.legend(['Original', 'Shifted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Load the fMRI Data<a id=\"load_fmri_data\"></a>\n",
    "\n",
    "Load in bold data, masks, and z-score the fMRI data. This time, load in all participants. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available ROIs:  ['FFA', 'PPA']\n"
     ]
    }
   ],
   "source": [
    "''' Regions of interests to focus on are Fusiform Face Area (FFA) and Parahippocampal Place Area (PPA)'''\n",
    "print('available ROIs: ', vdc_all_ROIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or no access: '/Users/SeanTraynor/Downloads/brainiak_datasets/vdc/sub-01/preprocessed/masks/sub-01_ventral_FFA_locColl_to_epi1.nii.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/nibabel/loadsave.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mstat_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/SeanTraynor/Downloads/brainiak_datasets/vdc/sub-01/preprocessed/masks/sub-01_ventral_FFA_locColl_to_epi1.nii.gz'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-dff69fc6a8a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Apply the function to pull out the mask data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mepi_mask_data_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_vdc_masked_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvdc_data_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvdc_all_ROIs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Check the dimensionality of the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CompSci/projects/2020NeuroAnalysisProject/2020-NeuroAnalysis-Project/brainiak_tutorials/utils.py\u001b[0m in \u001b[0;36mload_vdc_masked_data\u001b[0;34m(directory, subject_name, mask_list)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmask_counter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m# load the mask for the corresponding ROI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_vdc_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_counter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;31m# Cycle through the runs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CompSci/projects/2020NeuroAnalysisProject/2020-NeuroAnalysis-Project/brainiak_tutorials/utils.py\u001b[0m in \u001b[0;36mload_vdc_mask\u001b[0;34m(ROI_name, sub)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;31m# load the mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mmaskfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaskdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_ventral_%s_locColl_to_epi1.nii.gz\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mROI_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaskfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loaded %s mask\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mROI_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/nibabel/loadsave.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mstat_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No such file or no access: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstat_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mImageFileError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Empty file: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or no access: '/Users/SeanTraynor/Downloads/brainiak_datasets/vdc/sub-01/preprocessed/masks/sub-01_ventral_FFA_locColl_to_epi1.nii.gz'"
     ]
    }
   ],
   "source": [
    "roi_name = 'FFA'\n",
    "\n",
    "# Apply the function to pull out the mask data\n",
    "epi_mask_data_all = load_vdc_masked_data(vdc_data_dir, sub, vdc_all_ROIs)\n",
    "\n",
    "# Check the dimensionality of the data\n",
    "print('voxel by TR matrix - shape: ', epi_mask_data_all[vdc_all_ROIs.index(roi_name)].shape)\n",
    "print('label list - shape: ', stim_label_TR_shifted.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classification<a id=\"classification\"></a>\n",
    "\n",
    "Build a basic classifier to categorize data. \n",
    "\n",
    "For brain activity measured by fMRI, the voxel signals serve as the features. If we were showing pictures of faces, scenes, and objects, and collecting fMRI data while the subject was viewing the pictures, we know what picture was shown at each time-point. The stimulus type at each timepoint serves as the stimulus label. The signal from voxels at each timepoint correspond to the features of that picture. From this known set of stimulus labels and features, we can train a classifier to distinguish between pictures of faces, scenes, and objects.\n",
    "\n",
    "If the classifier makes predictions above chance (random guessing will lead to a 33.33% accuracy for 3 categories), the classifier has read out from the brain the category of the stimulus.\n",
    "\n",
    "In this example, an SVM classifier is used with hard-coded hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Reshape Data <a id=\"reshape_data\"></a>\n",
    "\n",
    "First, we extract the time points for which we have stimulus labels (only faces, places, and objects). That is, we drop the time-points from the BOLD signal that refer to the fixation periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epi_mask_data_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-bbb675e24cee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Pull out the data from this ROI for these time points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mroi_masked_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepi_mask_data_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvdc_all_ROIs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroi_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mbold_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreshape_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstim_label_TR_shifted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroi_masked_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#cleans up data and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'epi_mask_data_all' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract bold data for non-zero labels\n",
    "def reshape_data(label_TR_shifted, masked_data_all):\n",
    "    label_index = np.nonzero(label_TR_shifted)\n",
    "    label_index = np.squeeze(label_index)\n",
    "    # Pull out the indexes\n",
    "    indexed_data = np.transpose(masked_data_all[:,label_index])\n",
    "    nonzero_labels = label_TR_shifted[label_index] \n",
    "    return indexed_data, nonzero_labels #indices and corresponding labels \n",
    "\n",
    "# Pull out the data from this ROI for these time points\n",
    "roi_masked_data = epi_mask_data_all[vdc_all_ROIs.index(roi_name)]\n",
    "bold_data, labels = reshape_data(stim_label_TR_shifted, roi_masked_data) #cleans up data and labels\n",
    "\n",
    "# What is the dimensionality of the data? We need the first dim to be the same\n",
    "print('The %s has the dimensionality of: %d time points by %d voxels' % (roi_name, bold_data.shape[0], bold_data.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Leave-One-Run-Out (LORO) Training and Testing  <a id=\"loro_training_testing\"></a>\n",
    "\n",
    "Perform LORO cross-validation to train and test (other types of cross-validation can also be used). Can do folds of each run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1. Manually create a left-out run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stim_label_allruns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-ed5b9279723b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get run ids (works similarity to cv_ids)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstim_label_allruns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Select a run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mholdout_run_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stim_label_allruns' is not defined"
     ]
    }
   ],
   "source": [
    "# Get run ids (works similarity to cv_ids)\n",
    "run_ids = stim_label_allruns[5,:] - 1 \n",
    "\n",
    "# Select a run\n",
    "holdout_run_ids = 0\n",
    "\n",
    "# Make an index list with one run left out.\n",
    "train_runs = run_ids != holdout_run_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Normalization <a id=\"normalization\"></a>\n",
    "\n",
    "Reduce variance and bias through normalization. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(bold_data_, run_ids):\n",
    "    \"\"\"normalize the data within each run\n",
    "    \n",
    "    Parameters\n",
    "    --------------\n",
    "    bold_data_: np.array, n_stimuli x n_voxels\n",
    "    run_ids: np.array or a list\n",
    "    \n",
    "    Return\n",
    "    --------------\n",
    "    normalized_data\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    data = []\n",
    "    for r in range(vdc_n_runs):\n",
    "        data.append(scaler.fit_transform(bold_data_[run_ids == r, :]))\n",
    "    normalized_data = np.vstack(data)\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bold_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-8656e755a7c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbold_data_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbold_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'bold_data' is not defined"
     ]
    }
   ],
   "source": [
    "bold_data_normalized = normalize(bold_data, run_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Classifiers <a id=\"classifiers\"></a>\n",
    "\n",
    "Use a linear [support vector machine (SVM)](https://scikit-learn.org/stable/modules/svm.html). It is one of the most commonly used classifiers in cognitive neuroscience as it is robust to low number of training samples and outliers in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bold_data_normalized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-d1624880032d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Split the training set and test set ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbold_data_normalized\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_runs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_runs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# logical_not only uses holdout run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bold_data_normalized' is not defined"
     ]
    }
   ],
   "source": [
    "# Split the training set and test set ... \n",
    "X_train = bold_data_normalized[train_runs,]\n",
    "y_train = labels[train_runs]\n",
    "\n",
    "# logical_not only uses holdout run\n",
    "X_test = bold_data_normalized[np.logical_not(train_runs),] \n",
    "y_test = labels[np.logical_not(train_runs)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1. Build a classifier and test on the held out run.\n",
    "\n",
    "The `X_train` data was created by excluding one run. We use this to train a classifier and then test it on `X_test`, the dataset that was created from the held-out run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-e7620d3a563f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Compute your evaluation on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a classifier model for the training set \n",
    "model = LinearSVC(C=1)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Compute your evaluation on the test set\n",
    "score = model.score(X_test, y_test)\n",
    "print('Accuracy = %s' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result:** The accuracy of a classifier trained on data with one held out run was 88%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2. Build a classifier by training and testing on multiple folds.\n",
    "\n",
    "The `PredefinedSplit` method does this automatically. Use PredefinedSplit to split the data for LORO multiple folds. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-72edb7e2b399>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# split data according to run ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPredefinedSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'run_ids' is not defined"
     ]
    }
   ],
   "source": [
    "# loop over all runs \n",
    "scores = []\n",
    "\n",
    "# split data according to run ids \n",
    "ps = PredefinedSplit(run_ids)\n",
    "print(ps)\n",
    "\n",
    "# classifier \n",
    "model = LinearSVC() \n",
    "for train_index, test_index in ps.split():\n",
    "    X_train, X_test = bold_data_normalized[train_index], bold_data_normalized[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    # fit an svm\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # calculate the accuracy for the hold out run\n",
    "    score = model.score(X_test, y_test)\n",
    "    scores.append(score)\n",
    "    \n",
    "print('Accuracy across folds:', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3.3 Classifier Performance**  \n",
    "\n",
    "In the VDC dataset, we have 3 equally represented sets of stimuli, and thus random guessing will result in being correct 1/3 of the time. Using this logic, this classifier used fMRI data from a brain mask of the Fusiform Face Area to make highly statistically significant classifications on a single participant. Accuracy varied marginally between different folds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Perform Analysis on Multiple Participants <a id=\"perform_analysis\"></a>\n",
    "\n",
    "The next step is to run a classifier on a group of subjects. We will now create the condition variable, stim_label_TR, for all subjects and then use it to pull out the relevant participant data and then feed it into a classifier.\n",
    "\n",
    "Before you run this command, make sure you save your notebook. You will be loading in a lot of data and so it might run into memory issues and crash your job. If you do have issues, change how many cores/memory you are using when you launch this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:**<a id=\"ex2\"></a> Convert the classifier code above into a function called `decode` with the inputs of data, labels, and run_labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put code here. The function should output models and scores\n",
    "def decode(data, labels, run_labels): \n",
    "    #data is normalized BOLD data from each subject \n",
    "    #labels is stimulus being shown\n",
    "    \n",
    "    score = model.score(data, labels)\n",
    "    #run labels is run number \n",
    "    \n",
    "    return model, score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the function on this participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bold_data_normalized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-6071e1dd28cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#just do by combining the three subjects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbold_data_normalized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Decoding accuracy across the 3 folds: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bold_data_normalized' is not defined"
     ]
    }
   ],
   "source": [
    "# Run the function \n",
    "\n",
    "#bold_data_normalized should take data from ALL subjects, store in 1 massive array\n",
    "#just do by combining the three subjects \n",
    "\n",
    "models, scores = decode(bold_data_normalized, labels, run_ids)\n",
    "print('Decoding accuracy across the 3 folds: ', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3:** <a id=\"ex3\"></a> What is the average SVM accuracy for sub-01, sub-02 and sub-03?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or no access: '/Users/SeanTraynor/Downloads/brainiak_datasets/vdc/sub-01/preprocessed/masks/sub-01_ventral_FFA_locColl_to_epi1.nii.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/nibabel/loadsave.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mstat_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/SeanTraynor/Downloads/brainiak_datasets/vdc/sub-01/preprocessed/masks/sub-01_ventral_FFA_locColl_to_epi1.nii.gz'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-7631ac72c396>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#load in the data for each subject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmasked_data_sub_01\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_vdc_masked_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvdc_data_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sub-01'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvdc_all_ROIs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mFFA_masked_data_01\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepi_mask_data_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvdc_all_ROIs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroi_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mbold_data_01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_01\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreshape_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstim_label_TR_shifted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroi_masked_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CompSci/projects/2020NeuroAnalysisProject/2020-NeuroAnalysis-Project/brainiak_tutorials/utils.py\u001b[0m in \u001b[0;36mload_vdc_masked_data\u001b[0;34m(directory, subject_name, mask_list)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmask_counter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m# load the mask for the corresponding ROI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_vdc_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_counter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;31m# Cycle through the runs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CompSci/projects/2020NeuroAnalysisProject/2020-NeuroAnalysis-Project/brainiak_tutorials/utils.py\u001b[0m in \u001b[0;36mload_vdc_mask\u001b[0;34m(ROI_name, sub)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;31m# load the mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mmaskfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaskdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_ventral_%s_locColl_to_epi1.nii.gz\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mROI_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaskfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loaded %s mask\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mROI_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/nibabel/loadsave.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mstat_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No such file or no access: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstat_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mImageFileError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Empty file: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or no access: '/Users/SeanTraynor/Downloads/brainiak_datasets/vdc/sub-01/preprocessed/masks/sub-01_ventral_FFA_locColl_to_epi1.nii.gz'"
     ]
    }
   ],
   "source": [
    "#find the accuracy of a classifier across participants\n",
    "subs = ['sub-01', 'sub-02', 'sub-03']\n",
    "\n",
    "roi_name = 'FFA'\n",
    "\n",
    "#load in the data for each subject \n",
    "masked_data_sub_01 = load_vdc_masked_data(vdc_data_dir, 'sub-01', vdc_all_ROIs)\n",
    "FFA_masked_data_01 = epi_mask_data_all[vdc_all_ROIs.index(roi_name)]\n",
    "bold_data_01, labels_01 = reshape_data(stim_label_TR_shifted, roi_masked_data)\n",
    "\n",
    "masked_data_sub_02 = load_vdc_masked_data(vdc_data_dir, 'sub-02', vdc_all_ROIs)\n",
    "FFA_masked_data_02 = epi_mask_data_all[vdc_all_ROIs.index(roi_name)]\n",
    "bold_data_02, labels_02 = reshape_data(stim_label_TR_shifted, roi_masked_data)\n",
    "\n",
    "masked_data_sub_03 = load_vdc_masked_data(vdc_data_dir, 'sub-03', vdc_all_ROIs)\n",
    "FFA_masked_data_03 = epi_mask_data_all[vdc_all_ROIs.index(roi_name)]\n",
    "bold_data_03, labels_03 = reshape_data(stim_label_TR_shifted, roi_masked_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels_01' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-566f4f3815e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbold_data_01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#np.shape(labels_02)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_02\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbold_data_02\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels_01' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"labels\", np.shape(labels_01))\n",
    "print(\"data\", np.shape(bold_data_01))\n",
    "#np.shape(labels_02)\n",
    "print(\"labels\", np.shape(labels_02))\n",
    "print(\"data\", np.shape(bold_data_02))\n",
    "print(\"labels\", np.shape(labels_03))\n",
    "print(\"data\", np.shape(bold_data_03))\n",
    "\n",
    "#all the same size so just concatenate.\n",
    "all_labels = np.concatenate((labels_01, labels_02, labels_03), axis = 0)\n",
    "all_bold_data = np.concatenate((bold_data_01, bold_data_02, bold_data_03), axis = 0)\n",
    "print(np.shape(all_labels))\n",
    "print(all_labels)\n",
    "print(np.shape(all_bold_data))\n",
    "print(all_bold_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_bold_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-51b8861fd46d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mall_bold_data_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_bold_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_bold_data_normalized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.33\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_bold_data' is not defined"
     ]
    }
   ],
   "source": [
    "#perform a train test split \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "scaler = StandardScaler()\n",
    "all_bold_data_normalized = scaler.fit_transform(all_bold_data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_bold_data_normalized, all_labels, test_size = 0.33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-eb029ff43839>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfull_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Compute your evaluation on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "full_model = LinearSVC(C=1)\n",
    "\n",
    "# Fit the model\n",
    "full_model.fit(X_train, y_train)\n",
    "\n",
    "# Compute your evaluation on the test set\n",
    "score = full_model.score(X_test, y_test)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" The reason the above classification score is so high is due to the fact that it was trained\\non all the participants. Considering the classifier had seen fMRI data of all the subjects, this\\nis practically double dipping (classifiying data it has already seen). Similar to leaving out \\na run as done before let's train the classifier on 2 participants and see how it does when presented\\nwith data from a new participant. \""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#EXPLANATION\n",
    "''' The reason the above classification score is so high is due to the fact that it was trained\n",
    "on all the participants. Considering the classifier had seen fMRI data of all the subjects, this\n",
    "is practically double dipping (classifiying data it has already seen). Similar to leaving out \n",
    "a run as done before let's train the classifier on 2 participants and see how it does when presented\n",
    "with data from a new participant. '''\n",
    "\n",
    "#should try and extrapolate to a new participant \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bold_data_01' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-d557932c1de7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Step 1. Create an array of bold data from participants 1 and 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mbold_data_s1s2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbold_data_01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbold_data_02\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Step 2. Create an array of labels of this corresponding data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bold_data_01' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "'''Create an SVC model trained on data from participants 1 and 2 \n",
    "and test on participant 3 '''\n",
    "\n",
    "# Step 1. Create an array of bold data from participants 1 and 2 \n",
    "bold_data_s1s2 = np.concatenate((bold_data_01, bold_data_02), axis = 0)\n",
    "\n",
    "# Step 2. Create an array of labels of this corresponding data\n",
    "labels_s1s2 = np.concatenate((labels_01, labels_02), axis = 0)\n",
    "\n",
    "# Step 3. Normalize bold data of training data array from participants 1 and 2 using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "bold_data_s1s2_normalized = scaler.fit_transform(bold_data_s1s2)\n",
    "\n",
    "# Step 4. Normalize bold data of participant 3 \n",
    "bold_data_03_normalized = scaler.fit_transform(bold_data_03)\n",
    "\n",
    "# Step 5. Train SVC on normalized bold data of first 2 participants\n",
    "s1s2_model = LinearSVC(C=1)\n",
    "s1s2_model.fit(bold_data_s1s2_normalized, labels_s1s2)\n",
    "\n",
    "# Step 6. Test SVC model on participant 3\n",
    "score = s1s2_model.score(bold_data_03_normalized, labels_03)\n",
    "\n",
    "print(score)\n",
    "\n",
    "# Step 7. Try and incorporate predefined split fold testing (2.3.2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_participant_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-700a28744c0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_participant_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFFA_masked_data_01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFFA_masked_data_02\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFFA_masked_data_03\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbold_data_03\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_participant_test' is not defined"
     ]
    }
   ],
   "source": [
    "new_participant_test(FFA_masked_data_01, FFA_masked_data_02, FFA_masked_data_03)\n",
    "\n",
    "print(bold_data_03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.PredefinedSplit.html\n",
    "\n",
    "def new_participant_test(masked_data1, masked_data2, masked_data3):\n",
    "    print(\"here\")\n",
    "    # use cell 2.3.2 for help \n",
    "    # test SVC's on all participant combinations and see which performs the best... (1,2), (2,3), (1,3) \n",
    "    # test on non trained subject  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or no access: '/Users/SeanTraynor/Downloads/brainiak_datasets/vdc/sub-01/preprocessed/masks/sub-01_ventral_FFA_locColl_to_epi1.nii.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/nibabel/loadsave.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mstat_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/SeanTraynor/Downloads/brainiak_datasets/vdc/sub-01/preprocessed/masks/sub-01_ventral_FFA_locColl_to_epi1.nii.gz'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-69a4795252ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mroi_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'FFA'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Apply the function to pull out the mask data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mepi_mask_data_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_vdc_masked_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvdc_data_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvdc_all_ROIs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mroi_masked_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepi_mask_data_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvdc_all_ROIs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroi_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mbold_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreshape_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstim_label_TR_shifted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroi_masked_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CompSci/projects/2020NeuroAnalysisProject/2020-NeuroAnalysis-Project/brainiak_tutorials/utils.py\u001b[0m in \u001b[0;36mload_vdc_masked_data\u001b[0;34m(directory, subject_name, mask_list)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmask_counter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m# load the mask for the corresponding ROI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_vdc_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_counter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;31m# Cycle through the runs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CompSci/projects/2020NeuroAnalysisProject/2020-NeuroAnalysis-Project/brainiak_tutorials/utils.py\u001b[0m in \u001b[0;36mload_vdc_mask\u001b[0;34m(ROI_name, sub)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;31m# load the mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mmaskfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaskdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_ventral_%s_locColl_to_epi1.nii.gz\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mROI_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaskfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loaded %s mask\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mROI_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/nibabel/loadsave.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mstat_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No such file or no access: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstat_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mImageFileError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Empty file: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or no access: '/Users/SeanTraynor/Downloads/brainiak_datasets/vdc/sub-01/preprocessed/masks/sub-01_ventral_FFA_locColl_to_epi1.nii.gz'"
     ]
    }
   ],
   "source": [
    "# Insert code here\n",
    "subs = ['sub-01', 'sub-02', 'sub-03']\n",
    "\n",
    "print(vdc_n_runs) #3 runs\n",
    "\n",
    "for sub in subs:\n",
    "    roi_name = 'FFA'\n",
    "    # Apply the function to pull out the mask data\n",
    "    epi_mask_data_all = load_vdc_masked_data(vdc_data_dir, sub, vdc_all_ROIs)\n",
    "    roi_masked_data = epi_mask_data_all[vdc_all_ROIs.index(roi_name)]\n",
    "    bold_data, labels = reshape_data(stim_label_TR_shifted, roi_masked_data)\n",
    "    run_ids = stim_label_allruns[5, :] - 1\n",
    "    print(run_ids)\n",
    "    print(bold_data.shape)\n",
    "    bold_data_normalized = normalize(bold_data, run_ids)\n",
    "    models, scores = decode(bold_data_normalized[:,:5519], labels, run_ids)\n",
    "    print(models, scores)\n",
    "    \n",
    "    #don't have to train on classifier, \n",
    "    #simply normalize data, get necessary variables and test  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bold_data_normalized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-9e726093d336>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbold_data_normalized\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5519\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bold_data_normalized' is not defined"
     ]
    }
   ],
   "source": [
    "models, scores = decode(bold_data_normalized[:,-5519:], labels, run_ids)\n",
    "print(models, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or no access: '/Users/SeanTraynor/Downloads/brainiak_datasets/vdc/sub-03/preprocessed/masks/sub-03_ventral_FFA_locColl_to_epi1.nii.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/nibabel/loadsave.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mstat_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/SeanTraynor/Downloads/brainiak_datasets/vdc/sub-03/preprocessed/masks/sub-03_ventral_FFA_locColl_to_epi1.nii.gz'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-87f12c751d0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mroi_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'FFA'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Apply the function to pull out the mask data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mepi_mask_data_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_vdc_masked_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvdc_data_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvdc_all_ROIs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mroi_masked_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepi_mask_data_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvdc_all_ROIs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroi_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbold_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreshape_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstim_label_TR_shifted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroi_masked_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CompSci/projects/2020NeuroAnalysisProject/2020-NeuroAnalysis-Project/brainiak_tutorials/utils.py\u001b[0m in \u001b[0;36mload_vdc_masked_data\u001b[0;34m(directory, subject_name, mask_list)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmask_counter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m# load the mask for the corresponding ROI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_vdc_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_counter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;31m# Cycle through the runs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CompSci/projects/2020NeuroAnalysisProject/2020-NeuroAnalysis-Project/brainiak_tutorials/utils.py\u001b[0m in \u001b[0;36mload_vdc_mask\u001b[0;34m(ROI_name, sub)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;31m# load the mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mmaskfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaskdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_ventral_%s_locColl_to_epi1.nii.gz\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mROI_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaskfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loaded %s mask\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mROI_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/nibabel/loadsave.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mstat_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No such file or no access: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstat_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mImageFileError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Empty file: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or no access: '/Users/SeanTraynor/Downloads/brainiak_datasets/vdc/sub-03/preprocessed/masks/sub-03_ventral_FFA_locColl_to_epi1.nii.gz'"
     ]
    }
   ],
   "source": [
    "sub = 'sub-03'\n",
    "roi_name = 'FFA'\n",
    "# Apply the function to pull out the mask data\n",
    "epi_mask_data_all = load_vdc_masked_data(vdc_data_dir, sub, vdc_all_ROIs)\n",
    "roi_masked_data = epi_mask_data_all[vdc_all_ROIs.index(roi_name)]\n",
    "bold_data, labels = reshape_data(stim_label_TR_shifted, roi_masked_data)\n",
    "run_ids = stim_label_allruns[5, :] - 1\n",
    "print(run_ids)\n",
    "print(bold_data.shape)\n",
    "bold_data_normalized = normalize(bold_data, run_ids)\n",
    "models, scores = decode(bold_data_normalized[:,-5519:], labels, run_ids)\n",
    "print(models, scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bold_data_normalized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-9e726093d336>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbold_data_normalized\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5519\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bold_data_normalized' is not defined"
     ]
    }
   ],
   "source": [
    "models, scores = decode(bold_data_normalized[:,-5519:], labels, run_ids)\n",
    "print(models, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bold_data_normalized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-8a2be859d490>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbold_data_normalized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#450 x 7027\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'bold_data_normalized' is not defined"
     ]
    }
   ],
   "source": [
    "print(bold_data_normalized.shape) #450 x 7027 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modular vs. Distributed Processing <a id=\"modular_vs_distributed\"></a>\n",
    "\n",
    "The discovery of the Fusiform Face Area (FFA; Kanwisher, McDermott, and Chun, 1997; see also McCarthy, Puce, Gore, & Allison, 1997) was ground breaking for the field. The mean activity signal for face stimuli was larger than the mean for houses and objects. Thus, the FFA was preferential to faces, and by extension, it was inferred that all other cognitive processing must also be localized in brain regions yet to be discovered. \n",
    "\n",
    "The local nature of processing was challenged by another study (Haxby et al., 2001). Instead of looking at the mean activity of a set of voxels, this study examined the _pattern of activity_ of a set of voxels. Thus, if the mean activity was similar for two conditions, but the pattern of activity across a set of voxels was different across the two conditions, we can discriminate between the two conditions. Using this technique, it was shown that faces are not represented just in the FFA alone, but are distributed across a variety of brain regions. This led to the distributed view of face processing.\n",
    "\n",
    "In this section, you will perform a decoding analysis in the FFA and the parahippocampal place area (PPA) using the VDC dataset. To recap, the FFA was shown as a face processing region and the PPA as a scene processing region. Specifically, you will analyze the patterns of activity in these ROIs in the following ways: \n",
    "\n",
    ">1. Can we discriminate scenes vs. objects in the FFA?  \n",
    "      The FFA was shown to be a preferred region for face processing. If we can decode scenes vs. objects in this region, it implies that there is discriminable information for these two categories in the FFA. Thus, the FFA would not just represent faces, but scenes and/or objects too. Also, scenes would not be exclusively represented in the PPA. \n",
    "           \n",
    ">2. Can we discriminate faces vs. objects in the PPA?  \n",
    "      The PPA was shown to be a preferred region for scene processing. If we can decode faces vs. objects in this region, it implies that there is discriminable information for these two categories in the PPA. Thus, faces would not only be represented in the FFA. Also, the PPA would not just represent scenes, but faces and/or objects too.\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Prepare Data for Loading <a id=\"prepare_data\"></a>\n",
    "\n",
    "Get the data ready for analysis of one participant by organizing it by ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/SeanTraynor/Downloads/brainiak_datasets/vdc/sub-01/ses-day2/design_matrix/sub-01_localizer_01.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/SeanTraynor/Downloads/brainiak_datasets/vdc/sub-01/ses-day2/design_matrix/sub-01_localizer_01.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-99956942e9dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load subject labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mstim_label_allruns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_vdc_stim_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvdc_data_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Load the fMRI data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-f05f286513b0>\u001b[0m in \u001b[0;36mload_vdc_stim_labels\u001b[0;34m(vdc_data_dir, subject_id)\u001b[0m\n\u001b[1;32m      9\u001b[0m                                (subject_id, run))\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# Load in data from MATLAB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mstim_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mstim_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstim_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \"\"\"\n\u001b[1;32m    206\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m     \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m     \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmdict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mmat_reader_factory\u001b[0;34m(file_name, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \"\"\"\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mbyte_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mmjv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_matfile_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmjv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reader needs file name or open file-like object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/SeanTraynor/Downloads/brainiak_datasets/vdc/sub-01/ses-day2/design_matrix/sub-01_localizer_01.mat'"
     ]
    }
   ],
   "source": [
    "# choose a subject\n",
    "sub = 'sub-01';\n",
    "\n",
    "# Convert the shift from secs to TRs\n",
    "shift_size = int(vdc_hrf_lag / vdc_TR) \n",
    "\n",
    "# Load subject labels\n",
    "stim_label_allruns = load_vdc_stim_labels(vdc_data_dir,sub) \n",
    "\n",
    "# Load the fMRI data\n",
    "epi_mask_data_all = load_vdc_masked_data(vdc_data_dir, sub, vdc_all_ROIs)\n",
    "\n",
    "# Convert the timing into TR indexes\n",
    "TRs_run = int(epi_mask_data_all[0].shape[1] / vdc_n_runs)\n",
    "stim_label_TR = label2TR(stim_label_allruns, vdc_n_runs, vdc_TR, TRs_run)\n",
    "\n",
    "# Shift the data some amount\n",
    "stim_label_TR_shifted = shift_timing(stim_label_TR, shift_size)\n",
    "\n",
    "# Select and reshape FFA data \n",
    "bold_data_FFA, labels = reshape_data(\n",
    "    stim_label_TR_shifted, epi_mask_data_all[vdc_all_ROIs.index('FFA')])\n",
    "\n",
    "# Select and reshape PPA data \n",
    "bold_data_PPA, _ = reshape_data(\n",
    "    stim_label_TR_shifted, epi_mask_data_all[vdc_all_ROIs.index('PPA')])\n",
    "\n",
    "# Specify the classifiers that will be used\n",
    "svc = LinearSVC()\n",
    "\n",
    "# load run ids (works similarity to cv_ids)\n",
    "run_ids = stim_label_allruns[5,:] - 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Decoding the Fusiform Face Area (FFA)<a id=\"decoding_ffa\"></a>\n",
    "\n",
    "**Exercise 4:**<a id=\"ex4\"></a> Decode Objects vs. Scenes from the FFA and report mean LORO test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-f1c97066471c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mnewruns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mnewarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbold_data_FFA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#bold data for non face labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "# 1 faces, 2 scenes, 3 objects \n",
    "\n",
    "# only retain object and scene data and run a LORO test (remove one run for testing)\n",
    "\n",
    "# leave out unrelated labels, only retain 2 and 3 \n",
    "\n",
    "#iterate through labels... \n",
    "#if labels == 1 np.delete(bold_data_normalized, [i])\n",
    "newarr = []\n",
    "newruns = []\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] != 1: \n",
    "        newarr.append(bold_data_FFA[i]) #bold data for non face labels\n",
    "        newruns.append(run_ids[i]) #run id for non face labels\n",
    "        \n",
    "labels = np.delete(labels, np.where(labels == 1)) #delete labels for faces\n",
    "\n",
    "newruns = np.asarray(newruns) #turn into np array \n",
    "newFFA = np.asarray(newarr)\n",
    "\n",
    "holdout_run_ids = 1\n",
    "train_runs = newruns != holdout_run_ids #have to remove the runids of the 1s \n",
    "\n",
    "print(newruns.shape) #make 300, remove the run id at the place where label is removed \n",
    "\n",
    "#leave out runs \n",
    "X_train = newFFA[train_runs,]\n",
    "y_train = labels[train_runs]\n",
    "X_test = newFFA[np.logical_not(train_runs),]\n",
    "y_test = labels[np.logical_not(train_runs)]\n",
    "\n",
    "svc.fit(X_train, y_train)\n",
    "score = svc.score(X_test, y_test)\n",
    "print(score) #can predict with 89% acc. at times, not random\n",
    "\n",
    "#FFA has activity beyond facial recog\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Decoding the Parrahippocampal Place Area (PPA) <a id=\"decoding_ppa\"></a>\n",
    "\n",
    "**Exercise 5:**<a id=\"ex5\"></a> Decode Objects vs. Faces from the PPA and report mean LORO test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bold_data_PPA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-5106be14135f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#retain object and face data and run LORO test (remove one run for testing)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbold_data_PPA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msvcP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bold_data_PPA' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#retain object and face data and run LORO test (remove one run for testing)\n",
    "print(bold_data_PPA.shape)\n",
    "\n",
    "svcP = LinearSVC()\n",
    "\n",
    "newarr = []\n",
    "newruns = []\n",
    "\n",
    "for i in range(len(_)):\n",
    "    if _[i] != 2:\n",
    "        newarr.append(bold_data_PPA[i])\n",
    "        newruns.append(run_ids[i])\n",
    "        \n",
    "labels = np.delete(_, np.where(_ == 2))\n",
    "\n",
    "newruns = np.asarray(newruns)\n",
    "newPPA = np.asarray(newarr)\n",
    "print(labels)\n",
    "print(newPPA)\n",
    "\n",
    "holdout_run_ids = 1\n",
    "train_runs = newruns != holdout_run_ids \n",
    "\n",
    "X_train = newPPA[train_runs,]\n",
    "y_train = labels[train_runs]\n",
    "X_test = newPPA[np.logical_not(train_runs),]\n",
    "y_test = labels[np.logical_not(train_runs)]\n",
    "\n",
    "svcP.fit(X_train, y_train)\n",
    "score = svcP.score(X_test, y_test) \n",
    "#score is about average random of the time when differentiating showing that the PPA might be more modular than the FFA\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6:**<a id=\"ex6\"></a>  What can you infer about the processing of faces, objects, and scenes in the FFA and PPA? Say a few words about what this example can tell you about modular vs. distributed processing in the brain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A:** Most processing in the brain is relatively distributed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Novel contribution:** <a id=\"novel\"></a> be creative and make one new discovery by adding an analysis, visualization, or optimization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributions <a id=\"contributions\"></a> \n",
    "\n",
    "M. Kumar, C. Ellis and N. Turk-Browne produced the initial notebook 02/2018   \n",
    "T. Meissner minor edits  \n",
    "Q. Lu a lot of edits...   \n",
    "M. Kumar added section introductions.  \n",
    "K.A. Norman provided suggestions on the overall content and made edits to this notebook.  \n",
    "C. Ellis implemented feedback from cmhn-s19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
