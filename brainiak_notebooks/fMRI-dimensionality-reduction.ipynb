{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fMRI Dimensionality Reduction\n",
    "\n",
    "## Introduction\n",
    "fMRI analysis often has a dimensionality problem: we get approximately 100,000 voxels (features) per volume, but only 100s of time points or trials (examples). This makes it very hard for machine learning algorithms to model how each voxel contributes. This problem is dubbed the curse of dimensionality.\n",
    "\n",
    "In this notebook we are going to explore several methods to reduce the dimensionality of complex fMRI data. \n",
    "\n",
    "## Goal of this Script\n",
    "1. Learn to compute the covariance of a dataset.  \n",
    "2. Reduce the feature space using principal component analysis (PCA).  \n",
    "3. Interpret the meaning of PCA components.  \n",
    "4. Perform feature selection using cross-validation.  \n",
    "\n",
    "## Table of Contents\n",
    "* [1. Load the Data](#load_data)  \n",
    "\n",
    "* [2. Covariance](#covariance)  \n",
    "\n",
    "* [3. PCA](#pca)  \n",
    "    * [3.1 Plot PCA](#plot_pca)  \n",
    "    * [3.2 \"Scree\" Plots](#scree)  \n",
    "    * [3.3 Interpreting Components](#cog-relevance)  \n",
    "    * [3.4 Normalization](#pca-norm)  \n",
    "    * [3.5  PCA Dimensionality Reduction and Classification](#wb-pca-class)  \n",
    "\n",
    "\n",
    "* [4. Feature Selection](#feat)  \n",
    "    * [4.1 Feature Selection: Pipelines](#pipeline)  \n",
    "    * [4.2 Feature Selection: Univariate](#univariate)   \n",
    "\n",
    "[Contributions](#contributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset:** For this script we will use a localizer dataset from [Kim et al. (2017)](https://doi.org/10.1523/JNEUROSCI.3272-16.2017). \n",
    "\n",
    "The localizer consisted of 3 runs with 5 blocks of each category (faces, scenes and objects) per run. Each block was presented for 15s. Within a block, a stimulus was presented every 1.5s (1 TR). Between blocks, there was 15s (10 TRs) of fixation. Each run was 310 TRs. In the matlab stimulus file, the first row codes for the stimulus category for each trial (1 = Faces, 2 = Scenes, 3 = Objects). The 3rd row contains the time (in seconds, relative to the start of the run) when the stimulus was presented for each trial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(5000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 5 seconds\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter('ignore')\n",
    "\n",
    "# Import neuroimaging, analysis and general libraries\n",
    "import numpy as np\n",
    "from time import time\n",
    "import pandas as pd\n",
    "\n",
    "# Import plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, PredefinedSplit\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, RFECV, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "%matplotlib inline\n",
    "%autosave 5\n",
    "sns.set(style = 'white', context='poster', rc={'lines.linewidth': 2.5})\n",
    "sns.set(palette=\"colorblind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here're some constants, which is specific for VDC data:\n",
      "data dir = /Users/SeanTraynor/Downloads/brainiak_datasets/vdc\n",
      "ROIs = ['FFA', 'PPA']\n",
      "Labels = {1: 'Faces', 2: 'Scenes', 3: 'Objects'}\n",
      "number of runs = 3\n",
      "1 TR = 1.50 sec\n",
      "HRF lag = 4.50 sec\n",
      "num TRs per run = 310\n"
     ]
    }
   ],
   "source": [
    "# load some helper functions\n",
    "from utils import load_labels, load_data, blockwise_sampling, label2TR, shift_timing, reshape_data\n",
    "from utils import normalize, decode\n",
    "# load some constants\n",
    "from utils import vdc_data_dir, vdc_all_ROIs, vdc_label_dict, vdc_n_runs, vdc_hrf_lag, vdc_TR, vdc_TRs_run\n",
    "\n",
    "print('Here\\'re some constants, which is specific for VDC data:')\n",
    "print('data dir = %s' % (vdc_data_dir))\n",
    "print('ROIs = %s' % (vdc_all_ROIs))\n",
    "print('Labels = %s' % (vdc_label_dict))\n",
    "print('number of runs = %s' % (vdc_n_runs))\n",
    "print('1 TR = %.2f sec' % (vdc_TR))\n",
    "print('HRF lag = %.2f sec' % (vdc_hrf_lag))\n",
    "print('num TRs per run = %d' % (vdc_TRs_run))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the Data <a id=\"load_data\"></a>\n",
    "\n",
    "Load the data for one participant using helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_id = 1\n",
    "mask_name = '' #can be 'FFA' or 'PPA'\n",
    "# This is set in order to reduce memory demands in order to run within 4Gb, \n",
    "# however, if you want to make this run on whole brain, then set this to ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/SeanTraynor/Downloads/brainiak_datasets/vdc/sub-01/ses-day2/design_matrix/sub-01_localizer_01.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/SeanTraynor/Downloads/brainiak_datasets/vdc/sub-01/ses-day2/design_matrix/sub-01_localizer_01.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e4ce6739d173>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Load subject labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mstim_label_allruns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvdc_data_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Load run_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CompSci/projects/2020NeuroAnalysisProject/2020-NeuroAnalysis-Project/brainiak_tutorials/utils.py\u001b[0m in \u001b[0;36mload_labels\u001b[0;34m(directory, subject_name)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;31m# Load in data from matlab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mstim_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0mstim_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstim_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \"\"\"\n\u001b[1;32m    206\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m     \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m     \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmdict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mmat_reader_factory\u001b[0;34m(file_name, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \"\"\"\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mbyte_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mmjv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_matfile_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmjv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mybrainiak/lib/python3.6/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reader needs file name or open file-like object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/SeanTraynor/Downloads/brainiak_datasets/vdc/sub-01/ses-day2/design_matrix/sub-01_localizer_01.mat'"
     ]
    }
   ],
   "source": [
    "# Specify the subject name\n",
    "sub = 'sub-%.2d' % (sub_id)\n",
    "# Convert the shift into TRs\n",
    "shift_size = int(vdc_hrf_lag / vdc_TR)  \n",
    "\n",
    "# Load subject labels\n",
    "stim_label_allruns = load_labels(vdc_data_dir, sub)\n",
    "\n",
    "# Load run_ids\n",
    "run_ids_raw = stim_label_allruns[5,:] - 1 \n",
    "\n",
    "# Load the fMRI data using a mask\n",
    "epi_mask_data_all = load_data(vdc_data_dir, sub, mask_name=mask_name)[0]\n",
    "\n",
    "# This can differ per participant\n",
    "print(sub, '= TRs: ', epi_mask_data_all.shape[1], '; Voxels: ', epi_mask_data_all.shape[0])\n",
    "TRs_run = int(epi_mask_data_all.shape[1] / vdc_n_runs)\n",
    "\n",
    "# Convert the timing into TR indexes\n",
    "stim_label_TR = label2TR(stim_label_allruns, vdc_n_runs, vdc_TR, TRs_run)\n",
    "\n",
    "# Shift the data some amount\n",
    "stim_label_TR_shifted = shift_timing(stim_label_TR, shift_size)\n",
    "\n",
    "# Perform the reshaping of the data\n",
    "bold_data_raw, labels_raw = reshape_data(stim_label_TR_shifted, epi_mask_data_all)\n",
    "\n",
    "# Normalize raw data within each run\n",
    "bold_normalized_raw = normalize(bold_data_raw, run_ids_raw)\n",
    "\n",
    "# Down sample the data to be blockwise rather than trialwise. \n",
    "#We'll use the blockwise data for all the \n",
    "bold_data, labels, run_ids = blockwise_sampling(bold_data_raw, labels_raw, run_ids_raw)\n",
    "\n",
    "# Normalize blockwise data within each run\n",
    "bold_normalized = normalize(bold_data, run_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Important Consideration: Block Averaging</strong>\n",
    "<br>\n",
    "Previously, we have been using data from each trial. Within each block, the voxel activity is correlated across trials. Thus, it is common (and probably better) to take the average value of the activity within a block as your observation in decoding analyses in order to avoid concerns about non-independence. Mean values of activity or beta coefficients (from GLM) are commonly used in the literature.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Covariance <a id=\"covariance\"></a>\n",
    "\n",
    "To illustrate the building blocks behind dimensionality reduction we will calculate the whole brain covariance and correlation matrix. \n",
    "\n",
    "Memory demands can be reduced by implementing a mask on the data. There are nearly 1 million voxels in every volume acquired, of which about 15% are in the brain. The data matrix of >100,000 voxels and <1000 time points is very large, making any computations on all of this data very intensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The covariance of two variables is calculated as follows: $$ Cov(X,Y) = \\frac{\\sum_{1}^{N}(X-\\bar{X})(Y-\\bar{Y})}{(N-1)}$$\n",
    "where $\\mbox{  }  \\bar{X} = mean(X), \\mbox{  } \\bar{Y} = mean(Y), \\mbox{  } N = \\mbox{number of samples } $\n",
    "\n",
    "Here we compute the covariance between two blocks (i.e., their averaged patterns across voxels).\n",
    "(reference: [here]( https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.cov.html))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bold_normalized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a74ac21f601a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbold_normalized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbold_normalized\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbold_normalized\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bold_normalized' is not defined"
     ]
    }
   ],
   "source": [
    "print(bold_normalized.shape)\n",
    "\n",
    "X = bold_normalized[2]\n",
    "Y = bold_normalized[3]\n",
    "\n",
    "print(np.cov(X, Y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covariance is dependent on the unit and scale of the measurement. Its value is thus not easily interpretable or comparable across datasets -- e.g. is there a strong relationship between X and Y if the covariance is 200 as compared to 2 or 2000?\n",
    "\n",
    "Correlation solves this problem by normalizing the range of the covariance from -1 to +1.\n",
    "\n",
    "$$ Corr(X,Y) = \\frac{Cov(X,Y)}{\\sqrt{\\frac{\\sum_{1}^{N}(X-\\bar{X})^2}{(N-1)}}\\sqrt{\\frac{\\sum_{1}^{N}(Y-\\bar{Y})^2}{(N-1)}}}$$\n",
    "\n",
    "Compute the correlation between all pairs of blocks with a numpy function that calculates the block-by-block correlation matrix in one step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bold_normalized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9c209a98a4e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrcoef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbold_normalized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'bold_normalized' is not defined"
     ]
    }
   ],
   "source": [
    "print(np.corrcoef(bold_normalized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PCA <a id=\"pca\"></a>\n",
    "\n",
    "We will use principal component analysis (PCA) to **reduce the dimensionality** of the data. Some voxels may contain correlated information or no information and so the original voxel-dimensional data matrix (time-by-voxels) can be projected into a lower-dimensional \"component\" matrix space (time-by-component) without losing much information.\n",
    "\n",
    "![image](https://cdn-images-1.medium.com/max/1200/1*Iri_LDMXuz2Qac-8KPeESA.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bold_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b5c0a8c948b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# The number of components was chosen arbitrarily.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbold_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbold_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#5519 features --> 20 components\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bold_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Use the PCA function in scikit-learn to reduce the dimensionality of the data\n",
    "# The number of components was chosen arbitrarily.\n",
    "pca = PCA(n_components=20)\n",
    "bold_pca = pca.fit_transform(bold_data) #5519 features --> 20 components\n",
    "var= pca.explained_variance_ratio_\n",
    "\n",
    "print('Original data shape:', bold_data.shape)\n",
    "print('PCA data shape:', bold_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Plot PCA <a id=\"plot_pca\"></a>\n",
    "\n",
    "Let's visualize the variance in the data along different component dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bold_pca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4b7693c7e344>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_plots\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     axes[i].hist(bold_pca[:, components_to_plot[i]], \n\u001b[0m\u001b[1;32m     12\u001b[0m                  bins=n_bins)\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# mark the plots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bold_pca' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzwAAAD5CAYAAADiOzB0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3yOhf/H8fdGo0WIDVHJaco25DDmUA2b48oxp6nGhGlRTiH6VowcRs5LORNKWAmlKCHRQYl8fXWQH7aZw8bWsOv3h8eu3La5751vV6/n49Hj0e267vt+3/d1v7frc9/Xfc3FMAxDAAAAAGBBroUdAAAAAADyCwMPAAAAAMti4AEAAABgWQw8AAAAACyLgQcAAACAZTHwALA0TkQJAMC/GwMPkIXRo0fLy8sry/+GDx8uSZo9e7a8vLx08eLFQk7smBMnTmjo0KFq0qSJ6tWrp9DQUB08eDBbt3H16lX16NFDEydOzFGG9evXy8vLS4cPH850+eHDh+Xl5aX169dLkv766y95eXlpyZIlDt/HiRMn1K9fP508eTJHGa1oypQp8vPzk6+vr+bMmZOv9xUSEqInnngiX+8ju3bt2qW2bdvK29tbQUFBhR0n1+z16FZCQkIy/EyrXbu2/P399fzzz+t///tfhuukpKRoyZIl6t69uxo1aqR69eopODhY0dHRSkpKytFjuPnn5+jRo9WgQYMc3VZhut1+DwD/NkULOwDgzNzd3bV48eJMl91zzz2SpG7duql58+a66667CjJajpw7d059+/ZV8eLF9corr6hEiRJavHixQkJCtHbtWnl5edm9jcuXL2vEiBH6/vvv5ePjUwCpJU9PT61Zs0aVKlVy+Drbt2/Xrl278jHV7eW7777Tu+++qy5duqhz58669957CztSgXv99dd17do1LViwQHfffXdhxyl0VapU0ZQpU8zLV69e1V9//aWZM2eqV69e2rx5s8qWLStJOnnypAYMGKDTp0+rV69eGjRokNzc3PT9999r4cKF+vjjj7V48WLz52JODR48WL17987VbRSG2+n3APBvxMAD3EKRIkVUt27dW65ToUIFVahQoYAS5c4HH3yg//u//9OWLVv04IMPSpIaNmyoxo0ba9WqVfrPf/5zy+vv2LFDkZGROn/+fEHENbm5udndDri1hIQESVJwcPBt+Q56XkhISFBAQICaNWtW2FGcQvHixTP0qkGDBqpYsaL69u2r9evXKywsTNeuXdMLL7yg2NhYrV69WjVr1jTXb9q0qZo0aaI+ffpo6tSpioyMzFWm+++/P1fXLyy30+8B4N+IQ9qAXMrsUIatW7eqU6dO8vX1VcuWLbVy5Uo988wzGj16tKSsD9G6+RCV2bNnq2nTplqyZIn8/f3VokUL/fTTT5Kk3bt3q3fv3qpbt64aNGigiIgInThx4pZZu3Tpovfee88cdiSpaNGicnFxUWpq6i2ve/HiRQ0cOFC1atXSxo0bHX5+8kJmz9d7772njh07ytfXV35+fgoPD9exY8ckXX/e0ne8WrZsaT7vkvTZZ5+pR48eeuSRR9SoUSNFRETo999/z3B/ERERatSokerXr6+RI0dq2bJlNp+AhYSEKCIiQqNGjVL9+vXVoUMH/f3337p48aIiIyPVunVreXt7q169egoJCdH+/fvN66Zv54MHD6pPnz7y9fVV8+bNtWjRIiUlJWn8+PFq1KiR/Pz8NHr0aF26dOmWz09SUpJmzJihoKAg+fj4qFWrVpo9e7auXLki6fphQuHh4ZKkp59+OstP8vr166eAgIAM33taunSpatWqpb/++kuS9MMPP2jgwIHy8/NT7dq11axZM40dO1YXLlzIMmNAQIAGDx6c4Xm+ebsmJSUpMjJSjz76qLy9vdW2bVutXLnS5noXLlzQmDFj1Lx5c3l7e6tVq1aaPn16lq/hb775xuzohg0bbA6XPHv2rF599VW1bNlSPj4+ateunZYvX27zHGS1rTPjSH5J2rRpk3r06KF69eqZh9gtWLBAaWlp5jrXrl1TdHS02rRpI19fXwUEBCgqKirD4/z1118VGhqqOnXqyM/PT+PGjcvxIWaSVKdOHUkyf5589dVX+umnnxQaGmoz7KSrX7++hg4dqocffviWtxsbG6uXXnpJfn5+ql+/viZMmJDhsdx8SFtISIiGDx+upUuXmtuoS5cu+umnn3Tw4EH16NFDvr6+at26tT788EOb24qPj9eYMWPUtGlT+fj46Mknn9Qnn3xis05ISIiGDRum1atXKygoSN7e3mrTpo0++OADm/W2bdumLl26qF69eqpfv75CQ0P13Xffmcsz+z1w5MgRDRo0SE2bNlWdOnXUq1evDJ86p7/+J02apKZNm8rX11c9e/bU999/f8vnEkD28AkPYMfVq1cz/Jurq6tcXTN/v2Dr1q164YUXFBQUpKFDh+rUqVOaOXOmLl++rHbt2mX7/s+dO6dVq1YpMjJS8fHxevjhh/Xpp58qIiJCLVq0UFRUlC5duqR58+apR48eWr9+vcqXL5/pbZUpU0ZlypSRJF25ckV//vmnZs2apatXr+qpp566ZY7ixYvr448/VrVq1bL9GLJy7dq1TJ/fa9eu3fJ6H3/8sSZMmKDw8HD5+fnp7NmzmjlzpkJDQ7V9+3Z169ZNiYmJWrp0qebMmWPu4EdHR2v69OkKDg7WoEGDdO7cOc2bN0/du3fX2rVrVaVKFSUmJqp3794qUqSIxowZo7vvvlvLli3TtGnTMuTYvn27/P39NWfOHF24cEHFihXTM888o5MnT2rYsGGqVKmS/vrrL82ZM0dDhgzRF198oTvvvNO8/uDBgxUWFqbw8HAtXbpUU6dO1fr169WgQQPNmDFDu3fv1jvvvKPy5ctr2LBhmT4Xqamp6tOnj06cOKEhQ4aoZs2a2r9/vxYuXKhDhw5pwYIFGjx4sKpVq6Zp06Zp/Pjxql27dqa31aVLFw0bNkwHDhyw2encuHGjGjZsqMqVK+u///2v+vTpo2bNmunNN9+Um5ub9u7dq4ULF+qOO+7Qq6++esttdyupqakKDQ3V8ePHNWTIEFWvXl1ff/21Xn/9dcXFxWno0KGSpBdffFHHjx/XqFGj5OnpqQMHDuitt95SWlqaRowYkeF2a9eurTVr1ujZZ59Vw4YNNXjwYN1///1KSEhQ165ddeXKFT3//POqVKmSduzYoYkTJ+q3337T+PHjzdvIbFvnNP/atWv1yiuvqH///nrhhReUmpqqdevWKSoqSvfff7/5c2LcuHHatGmTQkND1aRJEx09elTTp09XfHy8zffnXn31VQ0cOFADBgzQvn37NHfuXLm6uuq1117L0XZI//5O+icWX3zxhSSpVatWWV7nueeeu+VtpqSkqE+fPrp8+bJGjhypsmXLauXKlRkGi8x88cUXOn78uF5++WVduXJFr732msLDw1W0aFH1799fzz33nBYsWKCxY8eqTp06qlq1qi5cuKAePXro77//1tChQ1W+fHl98sknGjp0qJKSktStWzfz9nft2qVjx44pIiJCpUqV0ttvv60xY8bIy8tL3t7eOnDggIYOHaru3btr+PDhunz5subNm6d+/fpp+/btmR7Gt3//fj3zzDN66KGH9Morr6ho0aJavXq1+vfvrxkzZtj8Lpg7d64aNGigSZMmKTk5WW+++aYGDx6sHTt2ZPo6A5B9DDzALSQmJma6c9ikSZMsv0A/ffp01atXT7NmzTL/rVq1aurTp0+OMly7dk0vvviiHn30UUnXzzoWGRkpb29vzZ8/3xy8/P391bp1a82fP9+hnc7w8HDt3LlTkjRo0CDzXd2suLm55emwI13fwc6Jffv2yd3dXc8995y5Q1CxYkXt2LFDly5dUoUKFczvqDz00EOqXLmyLl68qDlz5igwMFBTp041b6tJkyYKCgrSrFmzFBUVpeXLlysuLk4xMTHm423RooXat2+f4ZOgq1evasqUKeYOT2xsrNzc3PTaa6/psccekyQ1atRIaWlpGjt2rH799VebQ4hCQkL09NNPS7r+PaUvvvhCpUuXNndUmzVrpp07d9q8k3yz9evX6/Dhw5o/f74CAgIkXT/MqHTp0po0aZK+/PJLtWjRwvxUr3r16lkeHtiqVSuVKlVKmzZtMgee//3vfzp06JD5XY9ffvlFjzzyiN566y25ubmZz+H+/fu1d+/eLHM6IiYmRj/++KMWLlxoPn/NmjWTm5ub3n77bfXs2VPly5fXt99+q44dO6pDhw6Srj/H7u7uKlGiRKa3W6JECdWtW1dFihTRPffcYz7+6dOn6/Tp01q/fr0eeugh8/5cXV21bNky9e7d23wN3Lytc5P/t99+U8+ePW2Gs/STiOzdu1ft2rXTb7/9pvXr12vQoEHmoOTv76+UlBR98sknNp8wDRgwQAMHDpQkNW7cWHv27NHu3bsdes5vfMPh8uXLOnLkiCZNmiR3d3d16tRJknT69GlJuTvcbMOGDfrjjz+0YsUKNWzYUNI/vTp+/Pgtr3vp0iXNnz/ffCPn559/1qJFi/TGG2+Yg0vZsmXVrVs3/fjjj6pataqWLl2qkydP6sMPP1StWrXM+0tNTdW0adPUsWNHFS9e3Lz9RYsWmbf/4IMPKiAgQJ999pk58Fy7dk0DBw40h8CqVatq3bp1unTpUqavialTp+qee+7R8uXLzfsJCAhQ165dFRkZqTZt2pg/uz09PTVv3jy5uLhIkpKTkzV69Gh99913atKkSY6fcwD/YOABbsHd3V3Lli3L8O9Z7VidOHFCf/zxh0JCQmz+vWHDhrn6kviNh5H89ttvOnnypLp37660tDTzEJi7775bDRo00JdffunQbQ4YMED9+vXTzp07tXDhQp09e1avv/56jjPmxLRp01SlSpUM//7777+bZ8HLTJMmTfTee++pffv2at26tZo3b64GDRqoXr16WV7n+++/199//63g4GCbfy9fvryaNGli7qx//fXXqlWrls1wV7RoUbVv315z5861ua6Hh4fNzo6np6eWLl0q6fpO4u+//64//vhDn376qSRlOHznkUcesbktSRkGzzJlytzyzE979+5VyZIlzWEnXadOnTRp0iTt3btXLVq0yPL6N3Jzc1P79u21efNmjRs3Tm5ubtqwYYPc3d0VGBgoSXriiSf0xBNPKDU1VceOHdMff/yhY8eO6eTJk1l+6umor7/+WsWLF1fTpk1tdsRbtmypBQsWaPfu3erUqZP8/f31/vvv6/Tp02revLmaN29uDo7ZsXfvXtWoUcMcdtI9+eSTWrp0qfbu3Wu+Dm7e1rnJP2rUKEnXD3/7/fff9eeff+qXX36Ri4uLeRjivn37JElt2rSxuY+BAweaw026Ro0a2Vy+7777Mj3L2s2OHDmS6Rs6Dz30kN5++21VrFhRksztau+T11vZt2+fSpcubQ476bfbtm3bDL26WaVKlWw+tU7vyo2De/on1+mHVX799dd64IEHVL16dZtt0apVK3300Uc6ePCg+bxVrlzZ5vbTH3dycrIkyc/PT0WKFFHXrl0VFBSkpk2bqnHjxho5cmSmeZOTk/Xjjz+qT58+5rCT/niDg4MVGRmp48ePq3r16pKkevXqmcOO9M8na5cvX77l8wLAcQw8wC0UKVIkW2cii4uLkyTzzEY3Sv8lnRPlypUz///cuXOSpKioKEVFRWVY94477nDoNtPfwffz81NqaqpWrFih8PDwAv3ibfXq1TPsbErXB4xbadOmjWbPnq0VK1Zo+fLlevfdd3X33XerW7dueumll1SkSJEM10nfEcpsO3h4eCgxMVHS9eP+77vvvkzXuVlm23nz5s2aMWOGTpw4obvuuks1a9Y0d8Zu/m5MZoOzu7u7zeUbd4Qyc+HCBZvXR7q7775bbm5u5uNyVOfOnbVq1Sp9+eWXatmypWJiYtS2bVszV2pqqiZNmqQPP/xQKSkpqlChgry9vVW8eHG73wOz59y5c0pJSZG3t3emy8+cOSPp+qC8aNEiffLJJ4qMjFRkZKRq1KihESNGmJ+EOuLChQu33NY3PneZbeuc5j958qReffVVffXVV3J1ddX999+vevXqydXV1XyNpJ9kIrNte7Obzwzm6upq812grFSpUsXmUE03Nzd5enqar9d0lStXlnT9O1eZfYcnPa+7u7vNDv6Nzp8/n+nA6MjPxazeYLrx8NCbe3Lu3Dn98ccfWR6+mb4tbr4d6Z8BL/05rFOnjt59910tXrxY77//vlasWKE777xT7du319ixYzN09uLFizIMQ56enhnuN/3x3vgmRlb3z98QA/IOAw+Qh0qVKiXpn8HnRvHx8apataqkf34537xTYu/L6ZLM0+mGh4fr8ccfz1a+/fv3Kz4+PsO7xt7e3jIMQ6dPn75tzjQUGBiowMBAJScna//+/Vq3bp3eeecdValSRd27d8+w/q22TWxsrEqXLm2uFx8fn2Gds2fP2s303Xff6aWXXlKnTp20ePFic2c6JiZGn3/+ebYen6NKlSplnsjiRufPn1dqamqGnVd7fHx8VLNmTX388ccqWbKkTp06pc6dO5vLJ06cqA0bNuj1119XQECAuTMaGhqa4ZC/m9l7vZcsWVIeHh6aP39+ptdP34EsUaKEhg4dan5HbteuXYqOjlZERIR27dqlkiVLOvRYS5UqleXrQVK2nztH8huGoQEDBujKlStasWKFfH195ebmJsMwFBMTY66b3vOzZ8/aDD0JCQk6fPiw3UNQHVG8eHGH3tB57LHHtGzZMu3YsSPLgSd9gNuxY4fZtRuVKVMm09dp+mCX10qWLKnatWtneebJ9CHOUY0bN1bjxo2VmpqqH374QR999JHWrFmjcuXKZfh+XcmSJeXi4mK+jm6U09cWgNzhLG1AHqpataoqVaqkLVu22Pz7wYMHbf4AZvpO4qlTp2zW+/bbb+3eR7Vq1eTh4aHff/9dPj4+5n+1a9fWu+++q82bN2d53c2bN2v48OHmMfnpvvrqK7m5uZkDmbMbP368OdTceeedat68ud544w1JMp/nmz/lqVu3rooVK6ZNmzbZ/HtsbKz27t1rHt7StGlTHT161OZ7BWlpadq6davdXAcOHFBaWprCw8NtPjlI/66UI++6Z5efn58SExMzDFTpZ9K78RAiR3Xu3FlffvmlNmzYoAceeMDmBAbffvutfH19FRwcbL6OExIS9NNPP93y8ZUoUcLu6z39BBTu7u42r+30k1LEx8fr/PnzCggIML9DV7FiRXXr1k29e/dWSkpKtnag/fz89N///jfDH+7M6XPnSP6EhAQdO3bMPD14+veg9uzZoytXrpjPYfp9px8OmW7dunXq379/lmeJyw9NmjSRj4+P3n777Uy/b7N3715t375dAQEBmQ470vVeXbx40eaQW8MwtH379nzJ7Ofnpz/++EP33nuvzbY4cuSI5syZo5SUFIdva+7cuQoICFBqaqrc3NzUqFEjvfbaaypZsmSmf9jY3d1dvr6+2rZtm839pA+1np6emR7KCyD/8AkPkIdcXFz00ksv6cUXX9SwYcPUqVMnxcXFaebMmXJ1dTU/2SlVqpQaNmyo999/XzVq1NB9992nrVu3OjTwuLq6avjw4Ro1apTc3NzUtm1bSdLKlSv15Zdf6s0338zyus8++6w+/vhjhYWFafDgwbrrrru0efNmffTRRxo5cqT5rnJSUpKOHTuWo78tcezYMSUlJeXr381p0qSJ1qxZo5EjRyo4OFhpaWlavXq17rjjDvO7JumP5dNPP1WLFi1UrVo1DR48WFFRURo5cqTat2+v8+fPa968eXJ1ddWQIUMkXT9t8wcffKCwsDBFRESodOnSWr16tY4dO2b38LL0d90jIyPVq1cvpaamatOmTeYQmv6dgLzUqVMnrV69WiNGjNCQIUPk5eWlAwcOaOHChWrWrJmaNm2a7dsMDg7WtGnTtHHjRvN5SVenTh3FxMRoyZIlevjhh/Xnn3/q7bffVmJi4i2/w9OqVSvNnTtX06ZNU/PmzfXzzz9r6dKlNocvpp82vV+/fho4cKAefPBB/frrr5o1a5buvfde1ahRQ25ubqpRo4Zmz54tV1dX1apVS//3f/+nxYsXy9vbO1tfrH/22We1adMmc1vfe++92rlzp5YvX66nnnoq228AOJq/cuXKWrdunR588EGVK1fOPNGBi4uL+RqpWbOmOnbsqAULFsgwDDVo0EBHjhzRvHnz1KtXL4cOscsrrq6umjJlivr166fu3burd+/eatCgga5du6ZvvvlGq1atUo0aNTRhwoQsb6Njx45asWKFRowYoRdeeEGVK1fW+++/79B3jXIiNDRUMTEx6tu3r8LCwlSxYkUdOHBA8+bNk5+fn/k9HUf4+/tr3rx5Cg8PV+/eveXm5qaPP/5YiYmJWZ55c/jw4QoNDVXfvn0VGhqqO+64Q++9955++eUXTZ061e7PEgB5i4EHyGPt27eXYRjm6YDLly+viIgIvfXWWzbH2k+ePFkTJ05UZGSkihQpooCAAE2ZMkVhYWF27+PJJ5/U3XffbR7GU7RoUdWsWVNz585Vy5Yts7zefffdp9WrV2vmzJl64403lJiYqJo1ayoqKsrmF/ehQ4fUt29fDRkyRM8//3y2Hv9//vMf7du3T7/++mu2rpcdbdu21d9//61ly5YpIiJChmGodu3aWrRokXnM/mOPPaaGDRtq+vTp2rNnj6KjozVw4EDzxAKbN29WiRIl1LhxYy1cuNB8x7V06dJavny5Jk+erFdffVWurq4KDAxUz549tWHDhlvmSn/n991339Vzzz2nMmXKyNvbW++9955CQkL07bffZji5QG4VL15cy5cv16xZs/TOO+/o/PnzqlSpkgYNGqSwsLAcnUigbNmyevTRR/XFF1/oySeftFk2evRoGYahhQsX6vLly6pYsaKCgoLk4eGhN954Q0ePHs30sKcBAwbowoUL+uCDD7Rs2TLVqVNHCxcuVK9evWwey4oVKzRr1izNmzdPCQkJ8vDw0JNPPqkhQ4aYn4ZMnTpVb731lpYsWWIejvjYY4/pxRdfzNaOZNmyZbV27VrNmDFDM2bM0KVLl1SlShWNGzdOvXv3zvbz5mj++fPna9KkSRo/frxcXV113333afTo0frmm2+0d+9eXb16VUWLFtXkyZP14IMP6sMPP9TChQt17733Kjw8XKGhodnOllvVqlXT+++/r+XLl+vzzz/XihUrJF0/c9vzzz+vXr16Zfguy43uuOMOLVmyxNx2f//9tx599FENGTIk01O+51a5cuW0du1aRUVFacqUKUpMTFTFihXVr18/DRo0KFu3Va9ePc2bN08LFizQiBEjlJqaqho1amjmzJlZ9rlRo0ZatmyZZs+erZdfflnS9UOHFy1axB++BQqBi8G34oA89dFHH6lmzZo2O33nzp1Ts2bN9PLLL+f49NQoGD/++KPi4+MzDI7h4eE6deqU+QcrAQDA7YFPeIA89tFHH+nnn3/W0KFDVaVKFcXHx+vdd99VmTJl1L59+8KOBztOnz6tiIgIPfPMM3rsscdkGIa++OILbd++PV/eiQYAAPmLT3iAPHbhwgVFRUVp586diouLU6lSpeTv769hw4bl6m/xoOCsW7dOq1ev1m+//SZJ8vLyUv/+/W/5l+YBAIBzYuABAAAAYFmclhoAAACAZTHwAAAAALAsBh4AAAAAlsXAAwAAAMCyGHgAAAAAWJZDA09SUpI6dOigv/76K8Oyw4cPq3PnzgoKCtLYsWN19erVPA8J3E7oC+A4+gI4jr4AOWN34Pnxxx/Vs2dP/f7775kuHzFihMaPH6+tW7fKMAytXbs2rzMCtw36AjiOvgCOoy9AztkdeNauXasJEybI09Mzw7KTJ08qJSVFdevWlSR17txZW7ZsyfuUwG2CvgCOoy+A4+gLkHNF7a0wceLELJfFxsbKw8PDvOzh4aEzZ87kTTLgNkRfAMfRF8Bx9AXIuVydtCAtLU0uLi7mZcMwbC4D+Ad9ARxHXwDH0Rfg1ux+wnMrFSpUUFxcnHk5Pj4+049a7Tl37pLS0ozcRMm1smVL6OzZpELNQA7nzOHq6qIyZe7K9e3QF3L8G3LQl4ycYbuQw/ly5FVXpLzpC10hhzPnyG1fcjXwVKpUScWKFdOBAwdUv359bdy4US1atMj27aSlGYVesvQczoActpwlR27Rl/xBDlvOkiO36Ev+IIctZ8mRW3nRF7piixy2nCVHTuXokLawsDD99NNPkqRp06YpMjJSbdq00eXLl9W3b988DQjc7ugL4Dj6AjiOvgCOcTEMo9BHtrNnkwp9cvTwKKm4uMRCzUAO58zh6uqismVLFGqGG9EXcjhzDvqSkTNsF3I4Xw66klFhbxNyOG+O3PYlVyctAAAAAABnxsADAAAAwLIYeAAAAABYFgMPAAAAAMti4AEAAABgWQw8AAAAACyLgQcAAACAZTHwAAAAALAsBh4AAAAAlsXAAwAAAMCyGHgAAAAAWBYDDwAAAADLYuABAAAAYFkMPAAAAAAsi4EHAAAAgGUx8AAAAACwLAYeAAAAAJbFwAMAAADAshh4AAAAAFgWAw8AAAAAy2LgAQAAAGBZDDwAAAAALIuBBwAAAIBlMfAAAAAAsCwGHgAAAACWxcADAAAAwLIYeAAAAABYFgMPAAAAAMti4AEAAABgWQ4NPDExMWrXrp0CAwO1cuXKDMsPHTqkLl26KDg4WM8995wuXryY50GB2wFdARxHXwDH0Rcg5+wOPGfOnFFUVJRWrVqlDRs2aM2aNTp27JjNOhMnTlRERIQ2bdqkBx98UO+8806+BQacFV0BHEdfAMfRFyB37A48u3fvVuPGjVW6dGm5u7srKChIW7ZssVknLS1Nly5dkiQlJyerePHi+ZMWcGJ0BXAcfQEcR1+A3LE78MTGxsrDw8O87OnpqTNnztisM3r0aI0bN07NmjXT7t271aNHj7xPCjg5ugI4jr4AjqMvQO4UtbdCWlqaXFxczMuGYdhcTklJ0dixY7VkyRL5+vpq8eLFGjVqlKKjox0OUbZsiWzGzh8eHiULO4Ikcpb4XG4AABNZSURBVNzMWXLYUxBdkejLzchhy1ly2ENfCgc5bDlLDnvYFyt45LDlLDlyyu7AU6FCBe3fv9+8HBcXJ09PT/Py0aNHVaxYMfn6+kqSnnrqKc2aNStbIc6eTVJampGt6+Q1D4+SiotLLNQM5HDOHK6uLg79IiiIrkj0hRzOnYO+ZOQM24UczpfD0a5I7IuRgxzZ6Uum17e3gr+/v/bs2aOEhAQlJydr27ZtatGihbn8gQce0OnTp3X8+HFJ0vbt2+Xj45PjQMDtiq4AjqMvgOPoC5A7dj/hKV++vIYNG6a+ffvqypUr6tq1q3x9fRUWFqaIiAj5+PgoMjJSQ4cOlWEYKlu2rCZNmlQQ2QGnQlcAx9EXwHH0BcgdF8MwCvfzS/ExKjmcO0duP0bNa/SFHM6cg75k5AzbhRzOl4OuZFTY24Qczpsj3w9pAwAAAIDbFQMPAAAAAMti4AEAAABgWQw8AAAAACyLgQcAAACAZTHwAAAAALAsBh4AAAAAlsXAAwAAAMCyGHgAAAAAWBYDDwAAAADLYuABAAAAYFkMPAAAAAAsi4EHAAAAgGUx8AAAAACwLAYeAAAAAJbFwAMAAADAshh4AAAAAFgWAw8AAAAAy2LgAQAAAGBZDDwAAAAALIuBBwAAAIBlMfAAAAAAsCwGHgAAAACWxcADAAAAwLIYeAAAAABYFgMPAAAAAMti4AEAAABgWQw8AAAAACyLgQcAAACAZTHwAAAAALAshwaemJgYtWvXToGBgVq5cmWG5cePH1dISIiCg4PVr18/XbhwIc+DArcDugI4jr4AjqMvQM7ZHXjOnDmjqKgorVq1Shs2bNCaNWt07Ngxc7lhGBo0aJDCwsK0adMmPfTQQ4qOjs7X0IAzoiuA4+gL4Dj6AuSO3YFn9+7daty4sUqXLi13d3cFBQVpy5Yt5vJDhw7J3d1dLVq0kCQNHDhQvXv3zr/EgJOiK4Dj6AvgOPoC5E5ReyvExsbKw8PDvOzp6amDBw+al//880+VK1dOY8aM0eHDh1W1alW98sor2QpRtmyJbK2fXzw8ShZ2BEnkuJmz5LCnILoi0ZebkcOWs+Swh74UDnLYcpYc9rAvVvDIYctZcuSU3YEnLS1NLi4u5mXDMGwuX716Vfv27dOKFSvk4+OjmTNnavLkyZo8ebLDIc6eTVJampHN6HnLw6Ok4uISCzUDOZwzh6uri0O/CAqiKxJ9IYdz56AvGTnDdiGH8+VwtCsS+2LkIEd2+pLp9e2tUKFCBcXFxZmX4+Li5OnpaV728PDQAw88IB8fH0lShw4dbN51AP4t6ArgOPoCOI6+ALljd+Dx9/fXnj17lJCQoOTkZG3bts08RlSS6tWrp4SEBB05ckSS9Pnnn6t27dr5lxhwUnQFcBx9ARxHX4DcsXtIW/ny5TVs2DD17dtXV65cUdeuXeXr66uwsDBFRETIx8dHc+fO1bhx45ScnKwKFSrozTffLIjsgFOhK4Dj6AvgOPoC5I6LYRiFe8CmOG6UHM6dI7fHjeY1+kIOZ85BXzJyhu1CDufLQVcyKuxtQg7nzZHv3+EBAAAAgNsVAw8AAAAAy2LgAQAAAGBZDDwAAAAALIuBBwAAAIBlMfAAAAAAsCwGHgAAAACWxcADAAAAwLIYeAAAAABYFgMPAAAAAMti4AEAAABgWQw8AAAAACyLgQcAAACAZTHwAAAAALAsBh4AAAAAlsXAAwAAAMCyGHgAAAAAWBYDDwAAAADLYuABAAAAYFkMPAAAAAAsi4EHAAAAgGUx8AAAAACwLAYeAAAAAJbFwAMAAADAshh4AAAAAFgWAw8AAAAAy2LgAQAAAGBZDDwAAAAALIuBBwAAAIBlOTTwxMTEqF27dgoMDNTKlSuzXG/Hjh0KCAjIs3DA7YauAI6jL4Dj6AuQc0XtrXDmzBlFRUVp/fr1cnNzU48ePeTn56fq1avbrBcfH68pU6bkW1DA2dEVwHH0BXAcfQFyx+4nPLt371bjxo1VunRpubu7KygoSFu2bMmw3rhx4zRkyJB8CQncDugK4Dj6AjiOvgC5Y/cTntjYWHl4eJiXPT09dfDgQZt1li1bpocfflh16tTJUYiyZUvk6Hp5zcOjZGFHkESOmzlLDnsKoisSfbkZOWw5Sw576EvhIIctZ8lhD/tiBY8ctpwlR07ZHXjS0tLk4uJiXjYMw+by0aNHtW3bNi1ZskSnT5/OUYizZ5OUlmbk6Lp5xcOjpOLiEgs1AzmcM4erq4tDvwgKoisSfSGHc+egLxk5w3Yhh/PlcLQrEvti5CBHdvqS6fXtrVChQgXFxcWZl+Pi4uTp6Wle3rJli+Li4tSlSxcNGDBAsbGx6tWrV44DAbcrugI4jr4AjqMvQO7YHXj8/f21Z88eJSQkKDk5Wdu2bVOLFi3M5REREdq6das2btyo6OhoeXp6atWqVfkaGnBGdAVwHH0BHEdfgNyxO/CUL19ew4YNU9++ffXkk0+qQ4cO8vX1VVhYmH766aeCyAjcFugK4Dj6AjiOvgC542IYRuEesCmOGyWHc+fI7XGjeY2+kMOZc9CXjJxhu5DD+XLQlYwKe5uQw3lz5Pt3eAAAAADgdsXAAwAAAMCyGHgAAAAAWBYDDwAAAADLYuABAAAAYFkMPAAAAAAsi4EHAAAAgGUx8AAAAACwLAYeAAAAAJbFwAMAAADAshh4AAAAAFgWAw8AAAAAy2LgAQAAAGBZDDwAAAAALIuBBwAAAIBlMfAAAAAAsCwGHgAAAACWxcADAAAAwLIYeAAAAABYFgMPAAAAAMti4AEAAABgWQw8AAAAACyLgQcAAACAZTHwAAAAALAsBh4AAAAAlsXAAwAAAMCyGHgAAAAAWBYDDwAAAADLYuABAAAAYFkODTwxMTFq166dAgMDtXLlygzLP/vsMz3xxBMKDg7W4MGDdeHChTwPCtwO6ArgOPoCOI6+ADlnd+A5c+aMoqKitGrVKm3YsEFr1qzRsWPHzOVJSUl69dVXFR0drU2bNsnLy0uzZ8/O19CAM6IrgOPoC+A4+gLkjt2BZ/fu3WrcuLFKly4td3d3BQUFacuWLebyK1euaMKECSpfvrwkycvLS6dOncq/xICToiuA4+gL4Dj6AuROUXsrxMbGysPDw7zs6empgwcPmpfLlCmj1q1bS5JSUlIUHR2tkJCQbIUoW7ZEttbPLx4eJQs7giRy3MxZcthTEF2R6MvNyGHLWXLYQ18KBzlsOUsOe9gXK3jksOUsOXLK7sCTlpYmFxcX87JhGDaX0yUmJio8PFy1atVSp06dshXi7NkkpaUZ2bpOXvPwKKm4uMRCzUAO58zh6uri0C+CguiKRF/I4dw56EtGzrBdyOF8ORztisS+GDnIkZ2+ZHp9eytUqFBBcXFx5uW4uDh5enrarBMbG6tevXrJy8tLEydOzHEY4HZGVwDH0RfAcfQFyB27A4+/v7/27NmjhIQEJScna9u2bWrRooW5/Nq1axo4cKDatm2rsWPHZvqOA/BvQFcAx9EXwHH0Bcgdu4e0lS9fXsOGDVPfvn115coVde3aVb6+vgoLC1NERIROnz6tX375RdeuXdPWrVslSd7e3ry7gH8dugI4jr4AjqMvQO64GIZRuAdsiuNGyeHcOXJ73Gheoy/kcOYc9CUjZ9gu5HC+HHQlo8LeJuRw3hz5/h0eAAAAALhdMfAAAAAAsCwGHgAAAACWxcADAAAAwLIYeAAAAABYFgMPAAAAAMti4AEAAABgWQw8AAAAACyLgQcAAACAZTHwAAAAALAsBh4AAAAAlsXAAwAAAMCyGHgAAAAAWBYDDwAAAADLYuABAAAAYFkMPAAAAAAsi4EHAAAAgGUx8AAAAACwLAYeAAAAAJbFwAMAAADAshh4AAAAAFgWAw8AAAAAy2LgAQAAAGBZDDwAAAAALIuBBwAAAIBlMfAAAAAAsCwGHgAAAACWxcADAAAAwLIYeAAAAABYlkMDT0xMjNq1a6fAwECtXLkyw/LDhw+rc+fOCgoK0tixY3X16tU8DwrcDugK4Dj6AjiOvgA5Z3fgOXPmjKKiorRq1Spt2LBBa9as0bFjx2zWGTFihMaPH6+tW7fKMAytXbs23wIDzoquAI6jL4Dj6AuQO0XtrbB79241btxYpUuXliQFBQVpy5YtGjJkiCTp5MmTSklJUd26dSVJnTt31ltvvaVevXo5HMLV1SUn2fMcOWyRI3v3XxBdyU6e/EYOW+TI3v3Tl8JBDluFmSM7982+WMEjh63CzpHb+7c78MTGxsrDw8O87OnpqYMHD2a53MPDQ2fOnMlWiDJl7srW+vmlbNkShR1BEjlu5iw57CmIrkj05WbksOUsOeyhL4WDHLacJYc97IsVPHLYcpYcOWX3kLa0tDS5uPwzVRmGYXPZ3nLg34KuAI6jL4Dj6AuQO3YHngoVKiguLs68HBcXJ09PzyyXx8fH2ywH/i3oCuA4+gI4jr4AuWN34PH399eePXuUkJCg5ORkbdu2TS1atDCXV6pUScWKFdOBAwckSRs3brRZDvxb0BXAcfQFcBx9AXLHxTAMw95KMTExWrhwoa5cuaKuXbsqLCxMYWFhioiIkI+Pj44cOaJx48YpKSlJtWvXVmRkpNzc3AoiP+BU6ArgOPoCOI6+ADnn0MADAAAAALcjh/7wKAAAAADcjhh4AAAAAFgWAw8AAAAAy2LgAQAAAGBZBTbwxMTEqF27dgoMDNTKlSszLD98+LA6d+6soKAgjR07VlevXi2UHJ999pmeeOIJBQcHa/Dgwbpw4UKh5Ei3Y8cOBQQE5EsGR3IcP35cISEhCg4OVr9+/Qrt+Th06JC6dOmi4OBgPffcc7p48WK+5EhKSlKHDh30119/ZVhWUK9Rib5kN0c6+nLdv6kvdCV7OdLRlesKqisSfclODvpii77YytHr1CgAp0+fNh5//HHj3LlzxqVLl4yOHTsa//3vf23Wad++vfH9998bhmEYL7/8srFy5coCz5GYmGg0bdrUOH36tGEYhjFz5kzj9ddfL/Ac6eLi4ow2bdoYjz/+eJ5ncCRHWlqaERgYaOzcudMwDMOYOnWq8eabbxZ4DsMwjJ49exo7duwwDMMwIiMjjRkzZuR5jh9++MHo0KGDUbt2bePEiRMZlhfEa9Qw6Et2c6SjL//4t/SFrmQvRzq68o+C6Iph0Jfs5KAv9CU/+lIgn/Ds3r1bjRs3VunSpeXu7q6goCBt2bLFXH7y5EmlpKSobt26kqTOnTvbLC+oHFeuXNGECRNUvnx5SZKXl5dOnTpV4DnSjRs3TkOGDMnz+3c0x6FDh+Tu7m7+8bKBAweqd+/eBZ5DktLS0nTp0iVJUnJysooXL57nOdauXasJEyZk+tepC+o1KtGX7OZIR1/+8W/pC13JXo50dOUfBdEVib5kJwd9oS/50ZcCGXhiY2Pl4eFhXvb09NSZM2eyXO7h4WGzvKBylClTRq1bt5YkpaSkKDo6Wq1atSrwHJK0bNkyPfzww6pTp06e37+jOf7880+VK1dOY8aMUadOnTRhwgS5u7sXeA5JGj16tMaNG6dmzZpp9+7d6tGjR57nmDhxoho0aOBQxvx6jWZ2X/SFvmQnh/Tv6QtdyV4Oia4URlck+pKdHPSFvuRHXwpk4ElLS5OLi4t52TAMm8v2lhdUjnSJiYkaMGCAatWqpU6dOhV4jqNHj2rbtm0aPHhwnt93dnJcvXpV+/btU8+ePfXhhx/qvvvu0+TJkws8R0pKisaOHaslS5Zo165d6tWrl0aNGpXnOXKTsSDvi77QF/ri2P04S450dOU6upK9nAV1P86SIx19uY6+ZC9nVgpk4KlQoYLi4uLMy3FxcTYfU928PD4+PtOPsfI7h3R9cuzVq5e8vLw0ceLEPM/gSI4tW7YoLi5OXbp00YABA8xMBZ3Dw8NDDzzwgHx8fCRJHTp00MGDBws8x9GjR1WsWDH5+vpKkp566int27cvz3NkJ2N+vUYzuy/6Ql+yk+Pf1Be6kr0cdMX5upJZTvpCX+iL4zkdfZ0WyMDj7++vPXv2KCEhQcnJydq2bZt5LKIkVapUScWKFdOBAwckSRs3brRZXlA5rl27poEDB6pt27YaO3Zsvr2Dby9HRESEtm7dqo0bNyo6Olqenp5atWpVgeeoV6+eEhISdOTIEUnS559/rtq1axd4jgceeECnT5/W8ePHJUnbt283i19QCuo1KtGX7OagL//evtCV7OWgK87XFcl5XqfOkoO+0JdbyfHrNEenT8iBTZs2Ge3btzcCAwON6OhowzAMo3///sbBgwcNwzCMw4cPG126dDGCgoKMF1980fj7778LPMe2bdsMLy8vIzg42PxvzJgxBZ7jRidOnMi3M4M4kuOHH34wunTpYrRr184IDQ014uPjCyXHjh07jI4dOxodOnQwnn76aePPP//MlxyGYRiPP/64eVaQwniNGgZ9yU6OG9GXf19f6IrjOW5EVwq+K4ZBXxzJQV/oS7q87IuLYRhGPg9jAAAAAFAoCuwPjwIAAABAQWPgAQAAAGBZDDwAAAAALIuBBwAAAIBlMfAAAAAAsCwGHgAAAACWxcADAAAAwLIYeAAAAABY1v8D+YGcB2eCJykAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1008x252 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setting plotting parameter\n",
    "n_bins=75\n",
    "\n",
    "# Plot\n",
    "n_plots = 4\n",
    "components_to_plot = [0,1,2,19]\n",
    "f, axes = plt.subplots(1, n_plots, figsize=(14, 14/n_plots))\n",
    "st=f.suptitle(\"Figure 3.1. Histogram of values for each PC dimension \", fontsize=\"x-large\")\n",
    "\n",
    "for i in range(n_plots): \n",
    "    axes[i].hist(bold_pca[:, components_to_plot[i]], \n",
    "                 bins=n_bins)\n",
    "    # mark the plots \n",
    "    axes[i].set_title('PC Dimension %d'%(components_to_plot[i]+1))\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "    axes[i].set_xlabel('Value')    \n",
    "    axes[i].set_xticks([])\n",
    "    axes[i].set_yticks([])    \n",
    "\n",
    "f.tight_layout()\n",
    "st.set_y(0.95)\n",
    "f.subplots_adjust(top=0.75)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the relationship between variances across pairs of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot the low dim representation of the bold data\n",
    "\"\"\"\n",
    "# Setting plotting parameters\n",
    "alpha_val = .8\n",
    "cur_pals = sns.color_palette('colorblind', n_colors=vdc_n_runs)\n",
    "\n",
    "# Plot\n",
    "n_plots = 3 \n",
    "f, axes = plt.subplots(1, n_plots, figsize=(14,5))\n",
    "st=f.suptitle(\"Figure 3.2. Scatter plots comparing PCA dimensions \", fontsize=\"x-large\")\n",
    "\n",
    "# plot data\n",
    "axes[0].scatter(bold_pca[:, 0], bold_pca[:, 1], \n",
    "                alpha=alpha_val, marker='.', color = 'k')\n",
    "axes[1].scatter(bold_pca[:, 2], bold_pca[:, 3], \n",
    "                alpha=alpha_val, marker='.', color = 'k')\n",
    "axes[2].scatter(bold_pca[:, 18], bold_pca[:, 19], \n",
    "                alpha=alpha_val, marker='.', color = 'k')\n",
    "\n",
    "axes[0].set_title('PCA Dimensions\\n1 x 2')\n",
    "axes[1].set_title('PCA Dimensions\\n3 x 4')\n",
    "axes[2].set_title('PCA Dimensions\\n18 x 19')\n",
    "\n",
    "# modifications that are common to all plots \n",
    "for i in range(n_plots): \n",
    "    axes[i].axis('equal')\n",
    "    axes[i].set_xticks([])\n",
    "    axes[i].set_yticks([])\n",
    "\n",
    "f.tight_layout()\n",
    "st.set_y(0.95)\n",
    "f.subplots_adjust(top=0.75)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:** As we can see, there is evident variance between some principal components and others not as much. \n",
    "\n",
    "This can help illustrate how many principal components explain the variance in the data... what are the defining features in low dimensionality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 \"Scree\" Plots <a id=\"scree\"></a>\n",
    "\n",
    "A [\"scree\" plot](https://www.theanalysisfactor.com/factor-analysis-how-many-factors/) can depict the amount of variance in the original data that is explained by each component.\n",
    "\n",
    "The scree plot below shows how many components would be sufficient to account for most of the variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PCA' object has no attribute 'explained_variance_ratio_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-88d0a9521695>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m \u001b[0;31m#use var instead of eignevalcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbold_pca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ro-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Scree Plot'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Principal Component'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PCA' object has no attribute 'explained_variance_ratio_'"
     ]
    }
   ],
   "source": [
    "var = pca.explained_variance_ratio_ #use var instead of eignevalcount\n",
    "\n",
    "plt.plot(np.arange(0, bold_pca.shape[1]), var, 'ro-', linewidth=2)\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Eigenvalue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:** This data shows that the first 2 principal components account for most of the variance in the data. This affirms the PCA dimensionality scatter plots. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Interpreting Components  <a id=\"cog-relevance\"></a>\n",
    "\n",
    "Here we aim to attribute clusters to what they represent in the data. Let's have a look at what the PCA 1x2 plot clusters truly represent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scatter Plot 1:**  Principal Component 1 x Principal Component 2 with labels color coded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a6f32ba907c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# separate scatters by label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#faces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         plt.scatter(bold_pca[i, 0], bold_pca[i, 1],\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Plot the low dim representation of the bold data\n",
    "\"\"\"\n",
    "from matplotlib  import cm\n",
    "# Setting plotting parameters\n",
    "alpha_val = .8\n",
    "cur_pals = sns.color_palette('colorblind', n_colors=vdc_n_runs)\n",
    "\n",
    "# plot pca vals of each run with different color based on their label \n",
    "# PCA 1 and 2 for all rows \n",
    " \n",
    "# separate scatters by label \n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == 1: #faces\n",
    "        plt.scatter(bold_pca[i, 0], bold_pca[i, 1],\n",
    "                alpha=alpha_val, marker='.', color = 'r')\n",
    "    elif labels[i] == 2: #scenes \n",
    "        plt.scatter(bold_pca[i, 0], bold_pca[i, 1],\n",
    "                alpha=alpha_val, marker='.', color = 'y')\n",
    "    else: #objects \n",
    "        plt.scatter(bold_pca[i, 0], bold_pca[i, 1],\n",
    "                alpha=alpha_val, marker='.', color = 'b')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0eb83e37b254>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#figure out how to separate scatters by run id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'run_ids' is not defined"
     ]
    }
   ],
   "source": [
    "alpha_val = .8\n",
    "cur_pals = sns.color_palette('colorblind', n_colors=vdc_n_runs)\n",
    "\n",
    "#figure out how to separate scatters by run id  \n",
    "i = 0\n",
    "while i < len(run_ids):\n",
    "    i+=15\n",
    "    color = 'r'\n",
    "    print(i)\n",
    "    if i > 30:\n",
    "        color = 'b'\n",
    "    elif i > 15:\n",
    "        color = 'y'\n",
    "    plt.scatter(bold_pca[i-15:i, 0], bold_pca[i-15:i, 1], alpha=alpha_val, marker='.', color = color)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "#split up by run, likely shows that runs were not all metrically equal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:** The results of these plots show that between runs the fMRI data may not be metrically consistent. Bold data differs more due to run id rather than label. Below we will see methods that can be used to still classify bold data by label. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Normalization <a id=\"pca-norm\"></a>\n",
    "\n",
    "Previously we ran the PCA analysis without normalizing the data.\n",
    "\n",
    "The previous PCA was ran on bold_data. Here we will apply PCA on the same data after applying normalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bold_normalized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8ca0e441ecd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbold_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbold_normalized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m \u001b[0;31m#use var instead of eignevalcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bold_normalized' is not defined"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=20)\n",
    "bold_pca = pca.fit_transform(bold_normalized)\n",
    "\n",
    "var = pca.explained_variance_ratio_ #use var instead of eignevalcount\n",
    "print(var)\n",
    "\n",
    "print(bold_pca[19])\n",
    "plt.plot(np.arange(0, bold_pca.shape[1]), var, 'ro-', linewidth=2)\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Eigenvalue')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scree plot looks similar, although this doesn't indicate similarity in what the principal components represent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f24d45560877>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# separate scatters by label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#faces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         plt.scatter(bold_pca[i, 0], bold_pca[i, 1],\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "from matplotlib  import cm\n",
    "# Setting plotting parameters\n",
    "alpha_val = .8\n",
    "cur_pals = sns.color_palette('colorblind', n_colors=vdc_n_runs)\n",
    "\n",
    "# plot pca vals of each run with different color based on their label \n",
    "# PCA 1 and 2 for all rows \n",
    " \n",
    "# separate scatters by label \n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == 1: #faces\n",
    "        plt.scatter(bold_pca[i, 0], bold_pca[i, 1],\n",
    "                alpha=alpha_val, marker='.', color = 'r')\n",
    "    elif labels[i] == 2: #scenes \n",
    "        plt.scatter(bold_pca[i, 0], bold_pca[i, 1],\n",
    "                alpha=alpha_val, marker='.', color = 'y')\n",
    "    else: #objects \n",
    "        plt.scatter(bold_pca[i, 0], bold_pca[i, 1],\n",
    "                alpha=alpha_val, marker='.', color = 'b')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No evident clustering indicates the first 2 principal components may not be enough to explain the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 PCA Dimensionality Reduction and Classification <a id=\"wb-pca-class\"></a>\n",
    "\n",
    "Test some classifiers on dimensionalty reduced data ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline classification\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'bold_normalized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-6dc862d6b9de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Get baseline, whole-brain decoding accuracy without PCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Baseline classification'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Original size: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbold_normalized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0msvc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"linear\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bold_normalized' is not defined"
     ]
    }
   ],
   "source": [
    "# Run a basic n-fold classification\n",
    "\n",
    "# Get baseline, whole-brain decoding accuracy without PCA\n",
    "print('Baseline classification')\n",
    "print('Original size: ', bold_normalized.shape)\n",
    "svc = SVC(kernel=\"linear\", C=1)\n",
    "\n",
    "start = time()\n",
    "models, scores = decode(bold_normalized, labels, run_ids, svc)\n",
    "end = time()\n",
    "print('Accuracy: ', scores)\n",
    "print('Run time: %0.4fs' %(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bold_normalized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2e5bcfc21e01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run the classifier on data in component space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbold_pca_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbold_normalized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PCA (c=%d) classification'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbold_pca_normalized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'New size after PCA: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbold_pca_normalized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bold_normalized' is not defined"
     ]
    }
   ],
   "source": [
    "# Run the classifier on data in component space \n",
    "pca = PCA(n_components=20)\n",
    "bold_pca_normalized = pca.fit_transform(bold_normalized)\n",
    "print('PCA (c=%d) classification' % bold_pca_normalized.shape[1])\n",
    "print('New size after PCA: ', bold_pca_normalized.shape)\n",
    "\n",
    "start = time()\n",
    "models_pca, scores_pca = decode(bold_pca_normalized, labels, run_ids, svc)\n",
    "end = time()\n",
    "print('Accuracy: ', scores_pca)\n",
    "print('Run time: %0.4fs' %(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:** In this case PCA does not improve decoding accuracy. However, note that similar performance was achieved with 20 vs. 177,314 features, that the analysis ran 300-500x faster, and that the resulting model is likely to generalize better to new data (e.g., from a different subject)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, test how the number of components affects the accuracy of classifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bold_normalized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c01bb0b4e681>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbold_pca_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbold_normalized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PCA (c=%d) classification'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbold_pca_normalized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'New size after PCA: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbold_pca_normalized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bold_normalized' is not defined"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=14)\n",
    "bold_pca_normalized = pca.fit_transform(bold_normalized)\n",
    "print('PCA (c=%d) classification' % bold_pca_normalized.shape[1])\n",
    "print('New size after PCA: ', bold_pca_normalized.shape)\n",
    "\n",
    "start = time()\n",
    "models_pca, scores_pca = decode(bold_pca_normalized, labels, run_ids, svc)\n",
    "end = time()\n",
    "print('Accuracy: ', scores_pca)\n",
    "print('Run time: %0.4fs' %(end - start))\n",
    "\n",
    "#fewer components can decrease accuracy \n",
    "#4 components is enough for this example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:** Around 14 principal components are required for a high quality classifier. 5 principal components or more will give better than random accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Selection Using Cross-Validation <a id=\"feat\"></a>\n",
    "\n",
    "By taking a few PCA components instead of all voxels, a form of feature selection is being performed. Feature selection is used to reduce noise and increase computational speed. However, a problem with the approach above is that feature selection is applied to all data (prior to division into training and test sets) and is thus a kind of double dipping.\n",
    "\n",
    "A better way to select features is during cross-validation. In this case, feature selection is only performed on the training set, and the same features are used on the test data. This way the classifier never sees the test data during training.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<strong>Aside:</strong>  While doing PCA on the whole dataset violates the principle of never touch your test data during training, researchers have sometimes used this approach, justifying it on the grounds that  while PCA is using the fMRI data from the test set  it is not peeking at the class labels from the test set, and thus it will not bias classification accuracy. This is a topic of debate among researchers .\n",
    "</div>\n",
    "\n",
    "We will perform feature selection during cross-validation in this section. The `Pipelines` method in scikit-learn provides an easy interface to perform these steps and we will use it extensively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4.1 Pipelines: Feature selection with cross-validation  <a id=\"pipeline\"></a>\n",
    "\n",
    "Below we create a pipeline using scikit learn with the following steps:\n",
    "  \n",
    ">1. Perform dimensionality reduction.  \n",
    ">2. Run an SVM.\n",
    "\n",
    "To do this systematically during cross-validation, we will embed `Pipeline` in the `cross_validate` method in scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d03dc9a299b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Run the pipeline with cross-validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPredefinedSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Provides train/test indices to split data in train/test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m clf_pipe = cross_validate(\n\u001b[1;32m     10\u001b[0m     \u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbold_normalized\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'run_ids' is not defined"
     ]
    }
   ],
   "source": [
    "# Set up the pipeline\n",
    "pipe = Pipeline([\n",
    "    ('reduce_dim', PCA(n_components=20)),\n",
    "    ('classify', SVC(kernel=\"linear\", C=1)),\n",
    "])\n",
    "\n",
    "# Run the pipeline with cross-validation\n",
    "ps = PredefinedSplit(run_ids) # Provides train/test indices to split data in train/test sets\n",
    "clf_pipe = cross_validate(\n",
    "    pipe,bold_normalized,labels,cv=ps,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Print results from this dimensionality reduction technique\n",
    "print(clf_pipe)\n",
    "print (\"Average Testing Accuracy: %0.2f\" % (np.mean(clf_pipe['test_score'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the data indices that were used for training and testing. Ensure that they are different for each fold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9d1746524927>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Print train/test split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcv_idx\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbold_normalized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CV iteration: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcv_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train_index: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ps' is not defined"
     ]
    }
   ],
   "source": [
    "# Print train/test split\n",
    "for cv_idx ,(train_index, test_index) in enumerate(ps.split(bold_normalized, labels)):\n",
    "    print('CV iteration: %s' % cv_idx)\n",
    "    print('Train_index: ')\n",
    "    print(train_index)\n",
    "    print('Test_index: ')\n",
    "    print(test_index)\n",
    "\n",
    "# Print results from this dimensionality reduction technique\n",
    "print(clf_pipe)\n",
    "print (\"Average Testing Accuracy: %0.2f\" % (np.mean(clf_pipe['test_score'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Feature Selection: Univariate <a id=\"univariate\"></a>\n",
    "\n",
    "We can also use a variety of univariate methods to do feature selection in scikit-learn. One commonly used technique is to compute an ANOVA on the data and pick voxels with large F values. The F value measures the ratio of the variance between conditions (signal) to the variance within condition (noise). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the pipeline using ANOVA F-value (imported as `f_classif`) and the [`SelectKBest` method](http://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection) pick the top 100 voxels with the highest F values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-09e1362734d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Run the pipeline with cross-validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPredefinedSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Provides train/test indices to split data in train/test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m clf_pipe = cross_validate(\n\u001b[1;32m     11\u001b[0m     \u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbold_normalized\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'run_ids' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "# Insert code\n",
    "pipe = Pipeline([\n",
    "    ('reduce_dim', SelectKBest(k=100)),\n",
    "    ('classify', SVC(kernel=\"linear\", C=1)),\n",
    "])\n",
    "\n",
    "# Run the pipeline with cross-validation\n",
    "ps = PredefinedSplit(run_ids) # Provides train/test indices to split data in train/test sets\n",
    "clf_pipe = cross_validate(\n",
    "    pipe,bold_normalized,labels,cv=ps,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print(clf_pipe)\n",
    "print (\"Average Testing Accuracy: %0.2f\" % (np.mean(clf_pipe['test_score'])))\n",
    "\n",
    "#selectKbest gives 98% accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:** As can be seen in this example using the top 100 features with the highest F-values provides a much stronger classfier than the cross-validated PCA with 20 components. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributions <a id=\"contributions\"></a>\n",
    "\n",
    "M. Kumar, C. Ellis and N. Turk-Browne produced the initial notebook  02/2018  \n",
    "T. Meissner minor edits and added the ICA section  \n",
    "Q. Lu revise PCA plots, cb colors, code style improvement, leverage exisiting funcs  \n",
    "H. Zhang added pipeline section, use blockwise normalized data, other edits  \n",
    "M. Kumar enhanced section introductions.  \n",
    "K.A. Norman provided suggestions on the overall content and made edits to this notebook.  \n",
    "C. Ellis implemented comments from cmhn-s19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
